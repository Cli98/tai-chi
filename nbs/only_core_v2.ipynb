{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UnpackAI Library Development Plan\n",
    "> What library should we be?\n",
    "This proposal, is more of a branding proposal, targeting people who's going to play with AI, from various back grounds.\n",
    "* That means, we're going to talk about how people view this library, how they think of ```pip install -Uqq unpackai``` like if I have dandroff recengtly and my mind just jump right into the headshoulders.\n",
    "* For ML, currently, the **jump** is about the following, this is not a throught marketing research, just quick examples from a deep learning practitioner:\n",
    "    * Try free structure quickly, do experiments: pytorch\n",
    "    * Goes to production, run model on edge devices, Tensorflow\n",
    "    * Play with GPU accelerated tensor calculation: Jax\n",
    "    * Play with tf but in simpler layer sense: Keras\n",
    "    * Transformer in clean code: Huggingface\n",
    "    * Visualize things with interactive features: Plotly\n",
    "    * Deploy model prototype: streamlit\n",
    "* Surely you think I fail to mention ```fastai```, this is where the **branding goes wrong**, fastai library is bounded tightly with the education. It's considered a good creation along side its famous course, after the education. Its product feature has many limitation: docs too brief, not supporting multi-device training, very limited numbers of callbacks went beyond Jeremy H's own teaching.\n",
    "* Most important of all, ```fastai``` isn't enjoyable to use, **it's just packing many things mentioned in the course**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What we shouldn't be\n",
    "I know the course is life changing for me and I feel very grateful. But let's not be their library.\n",
    "\n",
    "### The pipeline wrapping plan\n",
    "It all started from a notebook, quite like a template notebook we have for the course. A notebook that achieves the data processing, model building, interpretation for a specific DL task.\n",
    "\n",
    "Then came the packaging part, we wrap **dozens of lines of codes**, which scares our kind students, into simple functions, or class.\n",
    "\n",
    "The wrapped functions are simple to use, to look at, it was executed in 1 line mostly. So friendly to our innocent students.\n",
    "\n",
    "This is what a python library is about, right? Wrap things into functions which can be further wraped into even less lines.\n",
    "\n",
    "It's nothing wrong about this approach at first. Some DL task, if need be, can be shrank into **less than 10 lines of codes.**\n",
    "* The 1st line load the data, \n",
    "* the 2nd line set how to transform data, \n",
    "* the 3rd line build/load the model, \n",
    "* the 4th line trained model.\n",
    "* the 5th line interpret the model in various ways\n",
    "\n",
    "Well the above do look like a decent **structure** to start with, then we pave out the tasks, different contributors take different tasks, can be developed in parallel, and we can have the agile/crum/kanban fun to track our progress!\n",
    "\n",
    "Even if we do this, we could build a useful product, no less.\n",
    "\n",
    "#### Bad side about pipeline wrapping plan\n",
    "So so many libraries are doing the same, from awesome people even. They usually end up to the following:\n",
    "* It's a mess of functions, among them many good functions but a mess. It ends up a branding disaster. (**There is no way to answer: what can you library do, in a slogan**)\n",
    "* A model zoo for a specific domain.\n",
    "* Wraping things up means less and less involvement from the user. The user will spend very little time play with the functions, and each function usually achieve very specific task. Actually I do believe there is a equilibrium like:\n",
    "$\\large{UserPlayHours = a * Task Transferability}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The salvation plan is somehow simpler at how we perceive the library:\n",
    "* A library that allows you experiment AI/DL for various tasks\n",
    "\n",
    "**BUT!!!**\n",
    "* Many module with in the pipeline should be dropdown-list/checkbox **Choosable**.\n",
    "* The **level of detail** we let them to play and choose, is the **level of the difficulty** we want them to enjoy\n",
    "\n",
    "### What is level of detail ?\n",
    "Level of details is the level of fuss we want user to focus on, this is the exact part fastai library got **WRONG**, which will explain most of our struggle so far:\n",
    "* It offers smooth/ easy pipelines, for newbies and business people even.\n",
    "* Any amount of reconfigure, is usually way too complicated for such audience\n",
    "* There is a **GAP** between the 2 points above, hence no room for playing\n",
    "\n",
    "#### Keras Example \n",
    "I started my AI journey with Keras, and I love keras by that time, because:\n",
    "* Keras plays with **layers**(eg. Linear, Convolution), its most strenth is at astracting details beneath this level, and let users play with layers. \n",
    "* I spent lots of time, having fun playing with layers\n",
    "* Aside from the things I have to redesign layer, I can deploy almost all kinds of models mentioned in any DL paper (ùëàùë†ùëíùëüùëÉùëôùëéùë¶ùêªùëúùë¢ùëüùë†=ùëé‚àóùëáùëéùë†ùëòùëáùëüùëéùëõùë†ùëìùëíùëüùëéùëèùëñùëôùëñùë°ùë¶)\n",
    "\n",
    "#### Pytorch lightning example\n",
    "Well I moved on to the career team. I have to deal with layer level, I have to deal with different data/forward pipeline. PL is a good library because:\n",
    "* It allows me play with the things I mentioned, but save my energy on things like looping, logging, multidevice training detail etc.\n",
    "* If you see a training notebook built by PL, you'll see very little lines around training template.\n",
    "* You'll find about a lots of lines on the specifications you intend to be different.\n",
    "\n",
    ">The branding image of the examples are simple:\n",
    "* Keras: play TensorFlow in a concept of layers\n",
    "* Pytorch-Lightning: writting less template code\n",
    "\n",
    "#### Unpackai Example\n",
    "For our lib, I intend for them to focus on, exactly the same range of things we want people to learn:\n",
    "* choose the columns they intend to use, in what way\n",
    "* choose the data transformations\n",
    "* choose the loss, the model structure to use (not keras.layer, not nn.module)\n",
    "* hit run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo of such example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "versions\n",
    "```json\n",
    "{\n",
    "  \"torch\": \"1.7.1\",\n",
    "  \"pytorch-lightning\": \"1.3.8\",\n",
    "  \"unpackai\": \"0.1.8.10\",\n",
    "  \"forgebox\": \"0.4.18.5\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, interact_manual\n",
    "from forgebox.imports import *\n",
    "from forgebox.category import Category\n",
    "from forgebox.html import DOM\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# for the purpose of easier developing\n",
    "# I'm using pytorch-lightning here\n",
    "# This is a questionable, tough and revokable dicision\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from typing import List, Dict, Callable, Any, Tuple\n",
    "from torchvision import transforms as tfm\n",
    "from PIL import Image\n",
    "from ipywidgets import (\n",
    "    VBox, HBox, HTML, Layout, Button,\n",
    "    Text, Textarea, IntSlider, FloatSlider, SelectMultiple, Dropdown, Checkbox\n",
    ")\n",
    "from typing import List, Dict, Any, Callable\n",
    "from forgebox.thunder.callbacks import DataFrameMetricsCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's skip data download here, I mean it's download, we're not going to reinvent brilliant stuff around download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 Everything starts with dataframe\n",
    "\n",
    "For fastai, everything starts from list, an **ItemList** to be specific. **ImageList** and **TextList** is [**ItemList**](https://fastai1.fast.ai/tutorial.itemlist.html) with some slight enhanced feature.```[üßÇ, üèì, üç∑, üêª]```\n",
    "\n",
    "For the clarity of education, or for simplecity as ultimate form of beauty, we use [**DataFrame**](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html) as starting point, ItemList in table format. In this way, every dataset has the same starting point, even the tabular data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase/ Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Phase:\n",
    "    \"\"\"\n",
    "    A configuration management mechanism\n",
    "    \"\"\"\n",
    "    is_phase = True\n",
    "    def __init__(self, **kwargs):\n",
    "        self.config = dict()\n",
    "        self.config.update(kwargs)\n",
    "        \n",
    "    def __setitem__(self, k, v):\n",
    "        self.config[k] = v\n",
    "    \n",
    "    def __getitem__(self, k):\n",
    "        return self.config[k]\n",
    "    \n",
    "    def __contains__(self, k):\n",
    "        return k in self.config\n",
    "    \n",
    "    def __call__(self):\n",
    "        return self.get_data(self.config)\n",
    "    \n",
    "    def get_data(self, raw):\n",
    "        \"\"\"\n",
    "        Reconstruct back to dict or list or value format\n",
    "        \"\"\"\n",
    "        if hasattr(raw,\"is_phase\"):\n",
    "            return raw.get_data(raw.config)\n",
    "        if type(raw) == list:\n",
    "            raw = list(self.get_data(i) for i in raw)\n",
    "            return raw\n",
    "        if type(raw) == dict:\n",
    "            for k, v in raw.items():\n",
    "                raw[k] = self.get_data(v)\n",
    "            return raw\n",
    "        return raw\n",
    "\n",
    "    def __str__(self):\n",
    "        return json.dumps(self(), indent=2)\n",
    "    \n",
    "    def __repr__(self,):\n",
    "        return f\"Phase:{self}\"\n",
    "    \n",
    "\n",
    "# class EnrichPhase(Phase):\n",
    "#     def __init__(self, *steps):\n",
    "#         super().__init__()\n",
    "#         self.config['steps'] = []\n",
    "#         for step in steps:\n",
    "#             checked = self.check_step(step)\n",
    "#             if checked:\n",
    "#                 self.config['steps'].append(checked)\n",
    "                \n",
    "#     def new_step(self, process, dst:str, src: str=None):\n",
    "#         self.config['steps'].append({\n",
    "#             \"process\":process,\n",
    "#             \"src\":src,\n",
    "#             \"dst\":dst\n",
    "#         })\n",
    "    \n",
    "#     def check_step(self,step):\n",
    "#         return step\n",
    "    \n",
    "def save_phase():\n",
    "    global phase\n",
    "    global PROJECT\n",
    "    PROJECT = Path(PROJECT)\n",
    "    PROJECT.mkdir(exist_ok=True, parents=True)\n",
    "    with open(PROJECT/\"phase.json\", \"w\") as f:\n",
    "        f.write(str(phase))\n",
    "        \n",
    "def load_phase():\n",
    "    global phase\n",
    "    global PROJECT\n",
    "    PROJECT = Path(PROJECT)\n",
    "    PROJECT.mkdir(exist_ok=True, parents=True)\n",
    "    if (PROJECT/\"phase.json\").exists():\n",
    "        with open(PROJECT/\"phase.json\", \"r\") as f:\n",
    "            phase = Phase(**json.loads(f.read()))\n",
    "            print(phase)\n",
    "    else:\n",
    "        phase = Phase()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Widget Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More or less\n",
    "And editable list within jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoreOrLess(VBox):\n",
    "    \"\"\"\n",
    "    Interactive list\n",
    "    You can add item to the list\n",
    "    Each added item has a remove button to remove such item\n",
    "    \"\"\"\n",
    "    def __init__(self, data_list: List[Any] = []):\n",
    "        super().__init__([])\n",
    "        for data in data_list:\n",
    "            self+data\n",
    "\n",
    "    def create_line(self, data):\n",
    "        children = list(self.children)\n",
    "        children.append(self.new_line(data))\n",
    "        self.children = children\n",
    "\n",
    "    @staticmethod\n",
    "    def data_to_dom(data):\n",
    "        return HTML(json.dumps(data))\n",
    "\n",
    "    def new_line(self, data) -> HBox:\n",
    "        del_btn = Button(description=\"Remove\", icon=\"trash\")\n",
    "        del_btn.button_style = 'danger'\n",
    "        hbox = HBox([del_btn, self.data_to_dom(data)])\n",
    "        hbox.data = data\n",
    "\n",
    "        def remove_hbox():\n",
    "            children = list(self.children)\n",
    "            for i, c in enumerate(children):\n",
    "                if id(c) == id(hbox):\n",
    "                    children.remove(c)\n",
    "            self.children = children\n",
    "        del_btn.click = remove_hbox\n",
    "        return hbox\n",
    "\n",
    "    def __add__(self, data):\n",
    "        self.create_line(data)\n",
    "        return self\n",
    "\n",
    "    def get_data(self):\n",
    "        \"\"\"\n",
    "        Return the data of this list\n",
    "        \"\"\"\n",
    "        return list(x.data for x in self.children)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### StepByStep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LivingStep:\n",
    "    def __init__(\n",
    "        self, func: Callable,\n",
    "        top_block: HTML = None\n",
    "    ):\n",
    "        self.output = Output()\n",
    "        self.func = func\n",
    "        self.top_block = top_block\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        with self.output:\n",
    "            if self.top_block is not None:\n",
    "                display(self.top_block)\n",
    "            return self.func(*args, **kwargs)\n",
    "        \n",
    "    def new_top_block(self, top_block):\n",
    "        self.top_block = top_block\n",
    "\n",
    "class StepByStep:\n",
    "    def __init__(self, funcs: Dict[str, Callable], top_board: HTML = None):\n",
    "        self.step_keys = list(funcs.keys())\n",
    "        self.steps = dict((k, LivingStep(f)) for k, f in funcs.items())\n",
    "        self.furthest = 0\n",
    "        self.current = -1\n",
    "        self.execute_cache = dict()\n",
    "        self.top_board = top_board\n",
    "        self.page_output = Output()\n",
    "        self.create_top_bar()\n",
    "        \n",
    "    def rerun(self,):\n",
    "        step = self.steps[self.step_keys[self.current]]\n",
    "        step.output.clear_output()\n",
    "        step()\n",
    "        \n",
    "    def create_control_bar(self,):\n",
    "        self.bar_hbox = list()\n",
    "        self.next_btn = Button(description=\"Next\", icon='check', button_style='info')\n",
    "        self.rerun_btn = Button(description=\"Rerun Step\", icon='play', button_style='success')\n",
    "        self.title = HTML(f\"<h4>Step By Step</h4>\")\n",
    "        self.next_btn.click = self.next_step\n",
    "        self.rerun_btn.click = self.rerun\n",
    "        self.bar_hbox.append(self.title)\n",
    "        self.bar_hbox.append(self.next_btn)\n",
    "        self.bar_hbox.append(self.rerun_btn)\n",
    "        return HBox(self.bar_hbox)\n",
    "\n",
    "    def create_top_bar(self):\n",
    "        self.vbox_list = []\n",
    "        if self.top_board is not None:\n",
    "            self.vbox_list.append(top_board)\n",
    "        self.progress_btns = dict(\n",
    "            (k, Button(\n",
    "                description=f\"{i+1}:{k}\",\n",
    "                icon=\"cube\",\n",
    "                button_style=\"danger\"\n",
    "                if i <= self.furthest else \"warning\"))\n",
    "            for i, (k, v) in enumerate(self.steps.items())\n",
    "        )\n",
    "        first_btn = list(self.progress_btns.values())[0]\n",
    "        first_btn.click = self.to_page_action(0)\n",
    "        self.progress_bar = HBox(list(self.progress_btns.values()))\n",
    "        self.vbox_list.append(self.progress_bar)\n",
    "        self.vbox_list.append(self.create_control_bar())\n",
    "        self.vbox_list.append(self.page_output)\n",
    "        self.widget = VBox(self.vbox_list)\n",
    "\n",
    "    def to_page_action(self, page_id):\n",
    "        \"\"\"\n",
    "        generate the button click event\n",
    "        \"\"\"\n",
    "        def to_page_func():\n",
    "            return self[page_id]\n",
    "        return to_page_func\n",
    "\n",
    "    def update_furthest(self):\n",
    "        if self.furthest < self.current:\n",
    "            if self.current<len(self):\n",
    "                # update even button\n",
    "                btn = self.progress_btns[self.step_keys[self.current]]\n",
    "                btn.click = self.to_page_action(\n",
    "                    self.current)\n",
    "                btn.button_style='danger'\n",
    "            self.furthest = self.current\n",
    "\n",
    "    def __getitem__(self, page_id):\n",
    "        \"\"\"\n",
    "        Display a single page\n",
    "        \"\"\"\n",
    "        if (page_id < 0) or (page_id >= len(self)):\n",
    "            return\n",
    "        self.current = page_id\n",
    "        key = self.step_keys[page_id]\n",
    "        step = self.steps[key]\n",
    "        self.title.value = f\"<h4 class='text-danger'>Step {page_id+1}: {key}</h4>\"\n",
    "        self.page_output.clear_output()\n",
    "\n",
    "        with self.page_output:\n",
    "            display(step.output)\n",
    "        if key not in self.execute_cache:\n",
    "            step()\n",
    "            self.execute_cache[key] = True\n",
    "\n",
    "    def next_step(self):\n",
    "        self.current += 1\n",
    "        if self.current >= len(self):\n",
    "            self.current = 0\n",
    "        self.update_furthest()\n",
    "        return self[self.current]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.step_keys)\n",
    "\n",
    "    def __call__(self):\n",
    "        display(self.widget)\n",
    "        self.next_step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### typings for interactives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typing for interactive details\n",
    "```self()``` will create widgets automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InteractiveTyping:\n",
    "    \"\"\"\n",
    "    Typing for interactive details\n",
    "    self.__call__() will create widgets directly\n",
    "    \"\"\"\n",
    "    name = \"anything\"\n",
    "    is_typing = True\n",
    "\n",
    "    def solid(self, default) -> None:\n",
    "        \"\"\"\n",
    "        Reset default value\n",
    "        \"\"\"\n",
    "        if default is not None:\n",
    "            self.default = default\n",
    "\n",
    "\n",
    "class INT(InteractiveTyping):\n",
    "    def __init__(self, min_: int = 0, max_: int = 10, step: int = 1, default: int = None):\n",
    "        self.max_ = max_\n",
    "        self.min_ = min_\n",
    "        self.step = step\n",
    "        self.default = default if default is not None else 1\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"int[{self.min_}-{self.max_}, :{self.step}]={self.default}\"\n",
    "\n",
    "    def __call__(self, default: int = None):\n",
    "        self.solid(default)\n",
    "        return IntSlider(\n",
    "            value=self.default,\n",
    "            min=self.min_,\n",
    "            max=self.max_,\n",
    "            step=self.step,\n",
    "        )\n",
    "\n",
    "\n",
    "class BOOL(InteractiveTyping):\n",
    "    def __init__(self, name:str=\"\", default: bool = True,):\n",
    "        self.default = default\n",
    "        self.name = name\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"bool={self.default}\"\n",
    "\n",
    "    def __call__(self, default: bool = None) -> Checkbox:\n",
    "        self.solid(default)\n",
    "        return Checkbox(value=self.default, description=self.name)\n",
    "\n",
    "\n",
    "class FLOAT(InteractiveTyping):\n",
    "    def __init__(self, min_: int = -1., max_: int = 1., step: int = .01, default: int = None):\n",
    "        self.max_ = max_\n",
    "        self.min_ = min_\n",
    "        self.step = step\n",
    "        self.default = default if default is not None else 0.01\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"float[{self.min_}-{self.max_}, :{self.step}]={self.default}\"\n",
    "\n",
    "    def __call__(self, default: int = None):\n",
    "        self.solid(default)\n",
    "        return FloatSlider(\n",
    "            value=self.default,\n",
    "            min=self.min_,\n",
    "            max=self.max_,\n",
    "            step=self.step,\n",
    "        )\n",
    "\n",
    "\n",
    "class STR(InteractiveTyping):\n",
    "    \"\"\"\n",
    "    String object\n",
    "    will create text or textarea\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, default: str = None, use_area: bool = False):\n",
    "        \"\"\"\n",
    "        use_area: do we use Textarea, if False,we use Text\n",
    "        \"\"\"\n",
    "        self.default = \"\" if default is None else default\n",
    "        self.use_area = use_area\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"str='{self.default}'\"\n",
    "\n",
    "    def __call__(self, default: str = None):\n",
    "        self.solid(default)\n",
    "        if self.use_area:\n",
    "            return Textarea(value=self.default, layout=Layout(width=\"80%\"))\n",
    "        return Text(value=self.default)\n",
    "\n",
    "\n",
    "class LIST(InteractiveTyping):\n",
    "    \"\"\"\n",
    "    dropdown list type or multiselection type\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, options: List[Any] = [], default: Any = None, multi: bool = False):\n",
    "        \"\"\"\n",
    "        if multi: default should be iterable\n",
    "        else: default should be one of the option\n",
    "        \"\"\"\n",
    "        self.options = options\n",
    "        self.default = default\n",
    "        self.multi = multi\n",
    "\n",
    "    def __repr__(self):\n",
    "        if self.multi:\n",
    "            size = f\"[0-{self.default}]/{len(self.options)}\"\n",
    "        else:\n",
    "            size = f\"1/{len(self.options)}\"\n",
    "        return f\"list,{size}\"\n",
    "\n",
    "    def __call__(self, default: Any = None):\n",
    "        self.solid(default)\n",
    "        if self.multi:\n",
    "            inter = SelectMultiple(options=self.options)\n",
    "        else:\n",
    "            inter = Dropdown(options=self.options)\n",
    "\n",
    "        if self.default is not None:\n",
    "            # if multi: default should be iterable\n",
    "            # else: default should be one of the option\n",
    "            inter.value = self.default\n",
    "        return inter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enhanced Interactive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original ```interact_manual``` isn't powerful enough for this situation, so the following is a more flexible way to decorate an interactive function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InteractiveAnnotations:\n",
    "    \"\"\"\n",
    "    Build interactive based on the info of function's ```__annotations__```\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, func: Callable,\n",
    "        icon: str = \"rocket\",\n",
    "        description: str = 'Run',\n",
    "        button_style='primary'\n",
    "    ):\n",
    "        self.func = func\n",
    "        self.icon = icon\n",
    "        self.button_style = button_style\n",
    "        self.description = description\n",
    "        self.build_vbox(func)\n",
    "\n",
    "    @classmethod\n",
    "    def on(\n",
    "        cls,\n",
    "        callback: Callable,\n",
    "        icon: str = 'rocket',\n",
    "        description: str = 'Run',\n",
    "        button_style: str = 'primary'\n",
    "    ) -> Callable:\n",
    "        \"\"\"\n",
    "        Use this class as a decorator\n",
    "        @InteractiveAnnotation.on(callback)\n",
    "        def target_func(a:STR(), b:INT()=1):\n",
    "            ...\n",
    "        \"\"\"\n",
    "        def decorator(func: Callable):\n",
    "            obj = cls(\n",
    "                func,\n",
    "                icon=icon,\n",
    "                description=description,\n",
    "                button_style=button_style\n",
    "            )\n",
    "            display(obj.vbox)\n",
    "            obj.register_callback(callback=callback)\n",
    "            return func\n",
    "        return decorator\n",
    "\n",
    "    def build_vbox(self, func: Callable):\n",
    "        row_list = []\n",
    "        self.fields = dict()\n",
    "        for k, v in func.__annotations__.items():\n",
    "            if hasattr(v, \"is_typing\") == False:\n",
    "                continue\n",
    "            widget = v()\n",
    "            widget.description = k\n",
    "            row_list.append(widget)\n",
    "            self.fields.update({k: widget})\n",
    "\n",
    "        # final button\n",
    "        self.final_btn = Button(\n",
    "            description=self.description,\n",
    "            icon=self.icon,\n",
    "        )\n",
    "        self.final_btn.button_style = self.button_style\n",
    "        row_list.append(self.final_btn)\n",
    "\n",
    "        # create interactive\n",
    "        self.vbox = VBox(row_list)\n",
    "        return self.vbox\n",
    "\n",
    "    def register_callback(\n",
    "        self,\n",
    "        callback: Callable\n",
    "    ) -> None:\n",
    "        def run_callback():\n",
    "            kwargs = self()\n",
    "            callback(kwargs)\n",
    "        self.final_btn.click = run_callback\n",
    "\n",
    "    def __call__(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        extract interactive data values\n",
    "        \"\"\"\n",
    "        rt = dict()\n",
    "        for k, widget in self.fields.items():\n",
    "            rt.update({k: widget.get_interact_value()})\n",
    "        return rt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test callback & decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4d601c7365047e0bd0f9e366b410a14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='', description='a'), IntSlider(value=1, description='b', max=10), Button(button_sty‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def print_stuff(kwargs):\n",
    "    print(kwargs)\n",
    "\n",
    "@InteractiveAnnotations.on(print_stuff, \"flask\", \"test\", button_style=\"warning\")\n",
    "def some_func(e, a:STR(), b:INT()=2, d=3):\n",
    "    print(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intercept interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_kwargs(kwargs):\n",
    "    print(kwargs)\n",
    "    return kwargs\n",
    "\n",
    "\n",
    "def reconfig_manual_interact(\n",
    "    widget,\n",
    "    description: str = \"Create\",\n",
    "    button_style: str = \"primary\",\n",
    "    icon: str = \"plus\"\n",
    ") -> Button:\n",
    "    \"\"\"\n",
    "    reconfigure the button of interactive features\n",
    "    \"\"\"\n",
    "    btn = None\n",
    "    for w in widget.children:\n",
    "        if type(w) == Button:\n",
    "            btn = w\n",
    "            break\n",
    "    btn.description = description\n",
    "    btn.button_style = button_style\n",
    "    btn.icon = icon\n",
    "    return btn\n",
    "\n",
    "\n",
    "def interact_intercept(\n",
    "    func:Callable,\n",
    "    result_cb: Callable = print_kwargs\n",
    "):\n",
    "    \"\"\"\n",
    "    Initialize a class with interactive features\n",
    "    \"\"\"\n",
    "    annotations = func.__annotations__\n",
    "    defaults = func.__defaults__\n",
    "    kwargs = dict()\n",
    "    if defaults is not None:\n",
    "        for (k, typing), default in zip(annotations.items(), defaults):\n",
    "            kwargs.update({k: typing(default)})\n",
    "    obj = dict()\n",
    "\n",
    "    def fillin_init(**kwargs):\n",
    "        obj.update({\n",
    "            \"kwargs\": kwargs,\n",
    "        })\n",
    "    f = interact_manual(fillin_init, **kwargs)\n",
    "\n",
    "    btn = reconfig_manual_interact(f.widget)\n",
    "\n",
    "    if btn is not None:\n",
    "        original = btn.click\n",
    "\n",
    "        def new_click_event():\n",
    "            original()\n",
    "            return result_cb(obj['kwargs'])\n",
    "        btn.click = new_click_event\n",
    "\n",
    "    return obj, f\n",
    "\n",
    "def init_interact(cls, result_cb: Callable = print_kwargs):\n",
    "    return interact_intercept(cls.__init__, result_cb=result_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36c10e8b74eb461e91ddb7d3432147c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='RGB')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "STR('RGB')()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enrich columns (feature transformation, label extraction)\n",
    "After this step, there will only be **MORE** column ‚ûï"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enrich Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Enrich:\n",
    "    \"\"\"\n",
    "    Enrich Base Class\n",
    "    Some default attributes\n",
    "    - is_enrich = True\n",
    "    - typing = None # output typing\n",
    "    - multi_cols = False # use multi-column as input\n",
    "    - prefer = None\n",
    "    - lazy = False  # shall we execute enrichment only through the iteration\n",
    "    - src = None # source column\n",
    "    \"\"\"\n",
    "    is_enrich = True\n",
    "    typing = None # output typing\n",
    "    multi_cols = False # use multi-column as input\n",
    "    prefer = None\n",
    "    lazy = False  # shall we execute enrichment only through the iteration\n",
    "    src = None # source column\n",
    "\n",
    "    def __init__(self): pass\n",
    "\n",
    "    def __call__(self, row):\n",
    "        return row\n",
    "    \n",
    "    def rowing(self, row):\n",
    "        if self.multi_cols:\n",
    "            return self(row)\n",
    "        else:\n",
    "            return self(row[self.src])\n",
    "\n",
    "\n",
    "class EnrichImage(Enrich):\n",
    "    \"\"\"\n",
    "    Create Image column from image path column\n",
    "    \"\"\"\n",
    "    prefer = \"QuantifyImage\"\n",
    "    typing = Image\n",
    "    lazy = True\n",
    "    \n",
    "\n",
    "    def __init__(\n",
    "        self, convert: STR(\"RGB\") = \"RGB\",\n",
    "        size: LIST(options=[28, 128, 224, 256, 512], default=224) = 224,\n",
    "    ):\n",
    "        self.convert = convert\n",
    "        self.size = size\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"[Image:{self.size}]\"\n",
    "\n",
    "    def __call__(self, x):\n",
    "        img = Image.open(x).convert(self.convert)\n",
    "        img = img.resize((self.size, self.size))\n",
    "        return img\n",
    "\n",
    "\n",
    "class ParentAsLabel(Enrich):\n",
    "    typing = str\n",
    "    prefer = \"QuantifyCategory\"\n",
    "    def __call__(self, path: Path,) -> str:\n",
    "        \"\"\"\n",
    "        Use parent folder name as label\n",
    "        \"\"\"\n",
    "        return Path(path).parent.name\n",
    "    \n",
    "ENRICHMENTS = dict(\n",
    "    EnrichImage=EnrichImage,\n",
    "    ParentAsLabel=ParentAsLabel,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5309ff3a8ff0418181750f49484e6e08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='RGB', description='convert'), Dropdown(description='size', index=2, options=‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "obj,f = init_interact(EnrichImage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Enrich üé∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_enrich(df):\n",
    "    global phase\n",
    "    DOM(f\"{len(df)} rows of data, example table\", \"h3\")()\n",
    "    display(df.sample(5))\n",
    "    display(HTML(\"<hr>\"))\n",
    "\n",
    "    def setting_col():\n",
    "        enrich_data_list = phase['enrich'] if 'enrich' in phase else []\n",
    "        enrich_box = MoreOrLess(enrich_data_list)\n",
    "        display(enrich_box)\n",
    "\n",
    "        \n",
    "        def set_enrich_(src=[\"[all_columns]\", ]+list(df.columns)):\n",
    "            DOM(f\"Setting up column enrich: {src}\", \"h4\")()\n",
    "            if src == \"[all_columns]\":\n",
    "                display(df.head(3))\n",
    "            else:\n",
    "                display(df[[src, ]].head(3))\n",
    "\n",
    "            def choose_enrich(dst=\"\", enrich=ENRICHMENTS):\n",
    "                DOM(f\"Source: {src}, Destination: {dst}, for {enrich.__name__}\", \"h4\")(\n",
    "                )\n",
    "                DOM(f\"{enrich.__doc__}\", \"quote\")()\n",
    "\n",
    "                def result_callback(kwargs):\n",
    "                    extra = {\"src\": src, \"dst\": dst,\n",
    "                                \"kwargs\": kwargs, \"enrich\": enrich.__name__}\n",
    "                    enrich_box+extra\n",
    "                    phase['enrich'] = enrich_box.get_data()\n",
    "                obj, decoed_func = init_interact(enrich, result_callback)\n",
    "            choose_enrich_widget = interact_manual(choose_enrich).widget\n",
    "            reconfig_manual_interact(\n",
    "                choose_enrich_widget,\n",
    "                description=\"Choose\", button_style='warning')\n",
    "        set_enrich_widget = interact_manual(set_enrich_).widget\n",
    "        reconfig_manual_interact(set_enrich_widget, button_style='warning')\n",
    "    setting_col()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute enrichment\n",
    "> apply the enrichment settings to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_enrich(\n",
    "    df: pd.DataFrame, phase:Phase\n",
    "):\n",
    "    if 'enrich' not in phase:\n",
    "        return df\n",
    "    for en_conf in tqdm(phase[\"enrich\"], leave=False):\n",
    "        enrich_name = en_conf['enrich']\n",
    "        enrich_cls = ENRICHMENTS[enrich_name]\n",
    "        kwargs = en_conf['kwargs']\n",
    "        src = en_conf['src']\n",
    "        dst = en_conf['dst']\n",
    "        # The class with lazy loading, will only \n",
    "        # call the class only if necessary\n",
    "        if enrich_cls.lazy:\n",
    "            obj = enrich_cls(**kwargs)\n",
    "            obj.src = src\n",
    "            df[dst] = obj\n",
    "        # The class without lazy loading\n",
    "        # create the column now\n",
    "        else:\n",
    "            obj = enrich_cls(**kwargs)\n",
    "            if src==\"[all_columns]\":\n",
    "                df[dst] = df.apply(obj, axis=1)\n",
    "            else:\n",
    "                df[dst] = df[src].apply(obj)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantify: Choose columns as X and Y, put them into number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Size classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SIZE_DIMENSION:\n",
    "    pass\n",
    "\n",
    "class BATCH_SIZE(SIZE_DIMENSION):\n",
    "    def __repr__(self): return f\"BATCH_SIZE\"\n",
    "\n",
    "class SEQUENCE_SIZE(SIZE_DIMENSION):\n",
    "    pass\n",
    "\n",
    "class IMAGE_SIZE(SIZE_DIMENSION):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantify classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Quantify:\n",
    "    is_quantify = True\n",
    "    \"\"\"\n",
    "    # From all things to number\n",
    "    The AI model does not understand anything, say, picture, text\n",
    "    Unless you transform it to integer and float tensors\n",
    "\n",
    "    Quantify and its subclass controls the\n",
    "        numericalization / collation of the data pipeline\n",
    "    The base class of quantify does: NOTHING\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, list_of_items):\n",
    "        return list(list_of_items)\n",
    "\n",
    "    def adapt(self, column):\n",
    "        \"\"\"\n",
    "        A function to let the data processing\n",
    "        adapt to the data column\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def __hash__(self,):\n",
    "        if hasattr(self, \"name\"):\n",
    "            return self.name\n",
    "        else:\n",
    "            return self.__class__.__name__\n",
    "\n",
    "\n",
    "class QuantifyImage(Quantify):\n",
    "    \"\"\"\n",
    "    Transform PIL.Image to tensor\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        mean_: LIST([\"imagenet\", \"0.5 x 3\"]) = \"imagenet\",\n",
    "        std_: LIST([\"imagenet\", \"0.5 x 3\"]) = \"imagenet\",\n",
    "    ):\n",
    "        if type(mean_) == str:\n",
    "            if mean_ == \"imagenet\":\n",
    "                mean_ = [0.485, 0.456, 0.406]\n",
    "            elif mean_ == \"0.5 x 3\":\n",
    "                mean_ = [.5, .5, .5]\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"Mean configuration: {mean_} not valid\")\n",
    "\n",
    "        if type(std_) == str:\n",
    "            if std_ == \"imagenet\":\n",
    "                std_ = [0.229, 0.224, 0.225]\n",
    "            elif std_ == \"0.5 x 3\":\n",
    "                std_ = [.5, .5, .5]\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"Standard Variation configuration: {std_} not valid\")\n",
    "\n",
    "        self.transform = tfm.Compose([\n",
    "            tfm.ToTensor(),\n",
    "            tfm.Normalize(mean=mean_, std=std_),\n",
    "        ])\n",
    "\n",
    "        self.shape = (BATCH_SIZE, 3, IMAGE_SIZE, IMAGE_SIZE)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Quantify Image to tensors:{self.transform}\"\n",
    "\n",
    "    def __call__(self, list_of_image):\n",
    "        return torch.stack(list(\n",
    "            self.transform(img) for img in list_of_image))\n",
    "\n",
    "\n",
    "class QuantifyText(Quantify):\n",
    "    def __init__(\n",
    "        self,\n",
    "        pretrained: STR(default=\"bert-base-cased\") = \"bert-base-cased\",\n",
    "        max_length: INT(default=512, min_=12, max_=1024, step=4) = 512,\n",
    "        padding: LIST(options=[\n",
    "            \"do_not_pad\",\n",
    "            \"max_length\",\n",
    "            \"longest\"], default=\"max_length\") = \"max_length\",\n",
    "        return_token_type_ids: BOOL(name=\"Token Type IDs\", default=True) = True,\n",
    "        return_attention_mask: BOOL(name=\"Attention Mask\", default=True) = True,\n",
    "        return_offsets_mapping: BOOL(name=\"Offset Mapping\", default=False) = False,\n",
    "    ):\n",
    "        self.pretrained = pretrained\n",
    "        self.max_length = max_length\n",
    "        self.padding = padding\n",
    "        self.return_token_type_ids = return_token_type_ids\n",
    "        self.return_attention_mask = return_attention_mask\n",
    "        self.return_offsets_mapping = return_offsets_mapping\n",
    "        self.truncation = True\n",
    "        self.return_tensors = 'pt'\n",
    "        self.shape = (BATCH_SIZE, SEQUENCE_SIZE)\n",
    "\n",
    "    def adapt(self, column):\n",
    "        \"\"\"\n",
    "        Initialize tokenizer\n",
    "        \"\"\"\n",
    "        from transformers import AutoTokenizer\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "            self.pretrained, use_fast=True)\n",
    "\n",
    "    def __call__(self, list_of_text: List[str]):\n",
    "        list_of_text = list(list_of_text)\n",
    "        return self.tokenizer(\n",
    "            list_of_text,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            truncation=self.truncation,\n",
    "            return_token_type_ids=self.return_token_type_ids,\n",
    "            return_attention_mask=self.return_attention_mask,\n",
    "            return_tensors=self.return_tensors,\n",
    "            return_offsets_mapping=self.return_offsets_mapping,\n",
    "        )\n",
    "\n",
    "\n",
    "class QuantifyCategory(Quantify):\n",
    "    \"\"\"\n",
    "    Transform single categorical data to index numbers in pytorch tensors\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        min_frequency: INT(min_=1, max_=20, default=1) = 1,\n",
    "    ):\n",
    "        self.min_frequency = min_frequency\n",
    "\n",
    "    def adapt(self, column):\n",
    "        # category statistics\n",
    "        value_counts = pd.DataFrame(column.value_counts())\n",
    "\n",
    "        # if minimun freq is 1\n",
    "        # very category occured should be accounted for\n",
    "        # hence no missing token padding is required\n",
    "        if self.min_frequency < 2:\n",
    "            self.category = Category(\n",
    "                arr=np.array(value_counts.index),\n",
    "                pad_mst=False)\n",
    "\n",
    "        # we need missing token\n",
    "        # for category's frequency < self.min_frequency\n",
    "        else:\n",
    "            categories = np.array(\n",
    "                list(value_counts.index[\n",
    "                    value_counts.values.reshape(-1) > self.min_frequency]))\n",
    "            self.category = Category(arr=categories, pad_mst=True)\n",
    "\n",
    "        self.shape = (BATCH_SIZE, len(self.category))\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Quantify Category:{self.category}\"\n",
    "\n",
    "    def __call__(self, list_of_strings):\n",
    "        return torch.LongTensor(self.category.c2i[np.array(list_of_strings)])\n",
    "\n",
    "\n",
    "class QuantifyNum(Quantify):\n",
    "    \"\"\"\n",
    "    Quantify contineous data, like float numbers\n",
    "    The only process is normalization on the entire population\n",
    "    \"\"\"\n",
    "    shape = (BATCH_SIZE, 1)\n",
    "\n",
    "    def adapt(self, column):\n",
    "        self.mean_ = column.mean()\n",
    "        self.std_ = column.std()\n",
    "\n",
    "    def __call__(self, list_of_num):\n",
    "        return (torch.FloatTensor(list_of_num)[:,None]-self.mean_)/self.std_\n",
    "\n",
    "    def backward(self, x):\n",
    "        return x*self.std_+self.mean_\n",
    "\n",
    "\n",
    "class QuantifyMultiCategory(Quantify):\n",
    "    \"\"\"\n",
    "    Turn Multi-categorical data to n_hot encoding numbers in pytorch tensors\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, col_name: str):\n",
    "        self.col_name = col_name\n",
    "\n",
    "\n",
    "QUANTIFY = dict(\n",
    "    Quantify=Quantify,\n",
    "    QuantifyNum=QuantifyNum,\n",
    "    QuantifyImage=QuantifyImage,\n",
    "    QuantifyCategory=QuantifyCategory,\n",
    "    QuantifyMultiCategory=QuantifyMultiCategory,\n",
    "    QuantifyText=QuantifyText,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pytorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaiChiDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A pytorch dataset working under our core engine\n",
    "    The dataset class should on be defined here once\n",
    "    \"\"\"\n",
    "    def __init__(self, df, columns: List[Any] = None):\n",
    "        self.df = df\n",
    "        self.columns = list(df.columns) if columns is None else columns\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def shuffle(self):\n",
    "        self.df = self.df.sample(frac=1.).reset_index(drop=True)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Dict[str, Any]:\n",
    "        row = dict(self.df.loc[idx])\n",
    "        rt = dict()\n",
    "        for col in self.columns:\n",
    "            v = row[col]\n",
    "            if hasattr(v, \"is_enrich\"):\n",
    "                rt[col] = v.rowing(row)\n",
    "            else:\n",
    "                rt[col] = v\n",
    "        return rt\n",
    "    \n",
    "    def split(\n",
    "        self,\n",
    "        valid_ratio:FLOAT(min_=0.01, max_=0.5, default=.1, step=0.01)=.1\n",
    "    ) -> Tuple[Any]:\n",
    "        \"\"\"\n",
    "        Split dataset to train, validation\n",
    "        \"\"\"\n",
    "        cls = self.__class__\n",
    "        slicing = (np.random.rand(len(self)) < valid_ratio)\n",
    "        return (\n",
    "            cls(self.df[~slicing].reset_index(drop=True), self.columns),\n",
    "            cls(self.df[slicing].reset_index(drop=True), self.columns)\n",
    "        )\n",
    "\n",
    "    def dataloader(\n",
    "        self,\n",
    "        batch_size: LIST(options=[1, 2, 4, 8, 16, 32, 64, 128, 256, 512], default=32) = 32,\n",
    "        shuffle: LIST(options=[True, False], default=False) = False,\n",
    "        num_workers: LIST(options=[0, 2, 4, 8, 16], default=0) =0,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Create dataloader from dataset\n",
    "        \"\"\"\n",
    "        return DataLoader(\n",
    "            self,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle,\n",
    "            num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose XY üé∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_xy(df):\n",
    "    global phase\n",
    "    DOM(f\"{len(df)} rows of data, example table\", \"h3\")()\n",
    "    display(df.sample(5))\n",
    "    display(HTML(\"<hr>\"))\n",
    "    DOM(\"Please Choose Column\", \"h3\")()\n",
    "    DOM(\"The AI model will try to guess the Y with the input X\", \"div\", {\"style\":\"color:#666699\"})()\n",
    "    \n",
    "    task = 'quantify'\n",
    "    # enrich by columns\n",
    "    if \"enrich\" in phase:\n",
    "        by_destination = dict((en['dst'], en) for en in phase['enrich'])\n",
    "    else:\n",
    "        by_destination = dict()\n",
    "    \n",
    "    data_list = phase[task] if task in phase else []\n",
    "    mol_box = MoreOrLess(data_list)\n",
    "    display(mol_box)\n",
    "\n",
    "    @interact_manual\n",
    "    def set_quantify_(src=list(df.columns), use_for = [\"As X\", \"As Y\"]):\n",
    "        DOM(f\"Quantify Column: {src} {use_for}\", \"h4\")()\n",
    "        display(df[[src, ]].head(3))\n",
    "        \n",
    "        quantify_dropdown = Dropdown(options=list(QUANTIFY.keys()))\n",
    "        \n",
    "        # check the hint from last step\n",
    "        prefer = None\n",
    "        if src in by_destination:\n",
    "            col_config = by_destination[src]\n",
    "            cls = ENRICHMENTS[col_config['enrich']]\n",
    "\n",
    "            # In case the enrich layer has the preference\n",
    "            if hasattr(cls, \"prefer\"):\n",
    "                prefer = cls.prefer\n",
    "                \n",
    "                # set default value to drop down value,\n",
    "                # if the the previous hint suggest so\n",
    "                quantify_dropdown.value = prefer\n",
    "                DOM(f\"Prefered quantifying:\\t{cls.prefer}\", \"h4\")()\n",
    "            if hasattr(cls, \"typing\"):\n",
    "                DOM(f\"Output data type:\\t{cls.typing}\", \"h4\")()\n",
    "        \n",
    "        @interact_manual\n",
    "        def choose_quantify(quantify = quantify_dropdown):\n",
    "            cls = QUANTIFY[quantify]\n",
    "            def result_callback(kwargs):\n",
    "                extra = {\"src\": src, \"x\":(use_for==\"As X\"),\n",
    "                        \"kwargs\": kwargs, \"quantify\": cls.__name__}\n",
    "                mol_box+extra\n",
    "                phase['quantify'] = mol_box.get_data()\n",
    "                \n",
    "            obj, decoded = init_interact(cls, result_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_quantify(\n",
    "    df: pd.DataFrame, phase:Phase\n",
    "):\n",
    "    # existance check\n",
    "    if 'quantify' not in phase:\n",
    "        raise KeyError(f\"No quantify stepset\")\n",
    "    \n",
    "    qdict = dict()\n",
    "    for i, qconf in tqdm(enumerate(phase['quantify']), leave = False):\n",
    "        qname = qconf['quantify']\n",
    "        kwargs = qconf['kwargs']\n",
    "        src = qconf['src']\n",
    "        x = qconf['x']\n",
    "        \n",
    "        cls = QUANTIFY[qname]\n",
    "        qobj = cls(**kwargs)\n",
    "        qobj.src = src\n",
    "        qobj.is_x = x\n",
    "        qobj.adapt(df[src])\n",
    "        qdict.update({src:qobj})\n",
    "    return qdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataloader\n",
    "This part handles:\n",
    "* Spliting\n",
    "* To dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaiChiCollate:\n",
    "    \"\"\"\n",
    "    Universal all power full collate function\n",
    "    1 for all collation\n",
    "    \"\"\"\n",
    "    def __init__(self, quantify_dict):\n",
    "        self.quantify_dict = quantify_dict\n",
    "        \n",
    "    def make_df(self, batch):\n",
    "        return pd.DataFrame(list(batch))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.quantify_dict)\n",
    "        \n",
    "    def __call__(self, batch) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        This call will execute the __call__(a_list_of_items)\n",
    "        from Quantify objects column by column\n",
    "        \"\"\"\n",
    "        batch_df = self.make_df(batch)\n",
    "        rt = dict()\n",
    "        for src,qobj in self.quantify_dict.items():\n",
    "            rt.update({\n",
    "                src:qobj(list(batch_df[src]))\n",
    "            })\n",
    "        return rt\n",
    "\n",
    "class TaiChiDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, dataset: TaiChiDataset, quantify_dict: Dict[str, Quantify]):\n",
    "        super().__init__()\n",
    "        self.dataset = dataset\n",
    "        self.quantify_dict = quantify_dict\n",
    "        \n",
    "        self.collate = TaiChiCollate(quantify_dict)\n",
    "        \n",
    "    def configure(\n",
    "        self,\n",
    "        valid_ratio:FLOAT(min_=0.01, max_=0.5, default=.1, step=0.01)=.1,\n",
    "        batch_size: LIST(options=[1, 2, 4, 8, 16, 32, 64, 128, 256, 512], default=32) = 32,\n",
    "        shuffle: LIST(options=[True, False], default=False) = True,\n",
    "        num_workers: LIST(options=[0, 2, 4, 8, 16], default=0) =0,\n",
    "    ):  \n",
    "        self.train_ds, self.val_ds = self.dataset.split(valid_ratio)\n",
    "        self.batch_size=batch_size\n",
    "        self.shuffle=shuffle\n",
    "        self.num_workers=num_workers\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        self.train_dl = self.train_ds.dataloader(\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=self.shuffle,\n",
    "            num_workers=self.num_workers)\n",
    "        self.train_dl.collate_fn = self.collate\n",
    "        return self.train_dl\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        self.val_dl = self.val_ds.dataloader(\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=self.shuffle,\n",
    "            num_workers=self.num_workers)\n",
    "        self.val_dl.collate_fn = self.collate\n",
    "        return self.val_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_datamodule(df, qdict, phase):\n",
    "    ds = TaiChiDataset(df)\n",
    "    datamodule = TaiChiDataModule(ds, qdict)\n",
    "    \n",
    "    def configure_setting(kwargs):\n",
    "        global phase\n",
    "        datamodule.configure(**kwargs)\n",
    "        phase['batch_level'] = kwargs\n",
    "    interact_intercept(datamodule.configure, configure_setting)\n",
    "    return datamodule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Choose your model, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import (\n",
    "    resnet18, resnet34, resnet50, resnet101, resnet152,\n",
    "    resnext101_32x8d, resnext50_32x4d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entry modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESNET_OPTIONS = {\"resnet18\": resnet18,\n",
    "                  \"resnet34\": resnet34,\n",
    "                  \"resnet50\": resnet50,\n",
    "                  \"resnet101\": resnet101,\n",
    "                  \"resnet152\": resnet152,\n",
    "                  \"resnext101_32x8d\": resnext101_32x8d,\n",
    "                  \"resnext50_32x4d\": resnext50_32x4d}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MidJoint1d(nn.Module):\n",
    "    def __init__(self, keys):\n",
    "        super().__init__()\n",
    "        self.keys = keys\n",
    "    \n",
    "    def forward(self, data):\n",
    "        tensors = list(data[key] for key in self.keys)\n",
    "        return torch.cat(tensors,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntryModel(nn.Module):\n",
    "    is_entry = True\n",
    "    \n",
    "    @classmethod\n",
    "    def from_quantify(cls, ):\n",
    "        raise ImportError(\n",
    "            f\"Please define class function 'from_quantify' for {cls.__name__}\"\n",
    "        )\n",
    "    \n",
    "class Empty(EntryModel):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.out_features=1\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x\n",
    "    \n",
    "    @classmethod\n",
    "    def from_quantify(cls,\n",
    "        quantify):\n",
    "        return cls()\n",
    "\n",
    "class ImageConvEncoder(EntryModel):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.name = \"cnn\"\n",
    "        self.output_shape = (BATCH_SIZE, model.fc.in_features)\n",
    "        self.out_features = model.fc.in_features\n",
    "        model.fc = Empty()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, data):\n",
    "        return self.model(data)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"\"\"ComputerVisionEncoder: {self.name}\n",
    "        Outputs shape:{self.output_shape}\"\"\"\n",
    "\n",
    "    @classmethod\n",
    "    def from_quantify(\n",
    "        cls,\n",
    "        quantify,\n",
    "        name: LIST(options=list(\n",
    "            RESNET_OPTIONS.keys()), default=\"resnet18\"),\n",
    "    ):\n",
    "        model = RESNET_OPTIONS[name](pretrained=True, progress=True,)\n",
    "        obj = cls(model)\n",
    "        obj.name = name\n",
    "        return obj\n",
    "\n",
    "\n",
    "class CategoryEncoder(EntryModel):\n",
    "    def __init__(self, num_embeddings, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.model = nn.Embedding(\n",
    "            num_embeddings,\n",
    "            embedding_dim)\n",
    "        \n",
    "    def forward(self, idx):\n",
    "        return self.model(idx)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_quantify(\n",
    "        cls,\n",
    "        quantify,\n",
    "        embedding_dim: LIST(\n",
    "            options=[4, 8, 16, 32, 64, 128, 256, 512], default=128) = 128):\n",
    "        num_embeddings = len(quantify.category)\n",
    "        obj = CategoryEncoder(\n",
    "            num_embeddings=num_embeddings,\n",
    "            embedding_dim=embedding_dim,\n",
    "        )\n",
    "        obj.out_features = embedding_dim\n",
    "        return obj\n",
    "\n",
    "\n",
    "class TransformerEncoder(EntryModel):\n",
    "    \"\"\"\n",
    "    A model part to encode sequnce data in to vectors\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, encoder_mode: BOOL(default=True) = True,):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.encoder_mode = encoder_mode\n",
    "\n",
    "    def forward(self, kwargs):\n",
    "        outputs = self.model(**kwargs)\n",
    "        if self.encoder_mode:\n",
    "            # output vector\n",
    "            if \"pooler_output\" in outputs:\n",
    "                return outputs.pooler_output\n",
    "            else:\n",
    "                return (\n",
    "                    outputs.last_hidden_state*kwargs['attention_mask'][:,:,None]\n",
    "                ).mean(1)\n",
    "        return outputs\n",
    "\n",
    "    @classmethod\n",
    "    def from_quantify(\n",
    "        cls,\n",
    "        quantify,\n",
    "        name: STR(default=\"bert-base-uncased\") = 'bert-base-uncased',\n",
    "        encoder_mode: BOOL(default=True) = True,\n",
    "    ):\n",
    "        from transformers import AutoModel\n",
    "        model = AutoModel.from_pretrained(name)\n",
    "        obj = cls(model)\n",
    "        obj.name = name\n",
    "        obj.encoder_mode = encoder_mode\n",
    "        if encoder_mode:\n",
    "            obj.out_features= model.config.hidden_size\n",
    "        return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entry = TransformerEncoder.from_quantify(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     vector = entry(data['review_content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entry = ImageConvEncoder.from_quantify(0,name=\"resnet18\")\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     vectors = entry(data['image'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exit modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_, y):\n",
    "    return (y_.argmax(-1) == y).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExitModel(nn.Module):\n",
    "    metric_funcs = dict()\n",
    "\n",
    "    def loss_step(self, x, y):\n",
    "        y_ = self(x)\n",
    "        loss = self.crit(y_, y)\n",
    "        metrics = dict()\n",
    "        for k, func in self.metric_funcs.items():\n",
    "            metrics.update({k:func(y_, y)})\n",
    "        return dict(loss=loss, y_=y_, **metrics)\n",
    "    \n",
    "class CategoryTop(ExitModel):\n",
    "    prefer = \"CrossEntropyLoss\"\n",
    "    input_dim = 2\n",
    "\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.top = nn.Linear(\n",
    "            in_features=in_features, out_features=out_features)\n",
    "        self.activation = nn.Softmax(dim=-1)\n",
    "        self.crit = nn.CrossEntropyLoss()\n",
    "        self.metric_funcs.update({\"acc\":accuracy})\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.top(x)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_quantify(cls, quantify, entry_part):\n",
    "        out_features = len(quantify.category)\n",
    "        in_features = entry_part.out_features\n",
    "        return cls(\n",
    "            in_features=in_features,\n",
    "            out_features=out_features,\n",
    "        )\n",
    "\n",
    "class MultiCategoryTop(ExitModel):\n",
    "    prefer = \"BCEWithLogitsLoss\"\n",
    "    input_dim = 2\n",
    "\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.top = nn.Linear(\n",
    "            in_features=in_features, out_features=out_features)\n",
    "        self.activation = nn.Sigmoid()\n",
    "        self.crit = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.top(x)\n",
    "    \n",
    "    def loss_step(self, x, y):\n",
    "        y_ = self(x)\n",
    "        loss = self.crit(y_, y)\n",
    "        return {\"loss\": loss, \"y_\": self.activation(y_)}\n",
    "    \n",
    "    @classmethod\n",
    "    def from_quantify(cls, quantify, entry_part):\n",
    "        out_features = len(quantify.category)\n",
    "        in_features = entry_part.out_features\n",
    "        return cls(\n",
    "            in_features=in_features,\n",
    "            out_features=out_features,\n",
    "        )\n",
    "\n",
    "\n",
    "class RegressionTop(ExitModel):\n",
    "    prefer = \"MSELoss\"\n",
    "    input_dim = 2\n",
    "\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.top = nn.Linear(\n",
    "            in_features=in_features, out_features=out_features)\n",
    "        self.crit = nn.MSELoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.top(x)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_quantify(cls, quantify, entry_part):\n",
    "        out_features = 1\n",
    "        in_features = entry_part.out_features\n",
    "        return cls(\n",
    "            in_features=in_features,\n",
    "            out_features=out_features,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EntireModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping quantify to the following entry or exit model\n",
    "QUANTIFY_2_ENTRY_MAP = dict({\n",
    "    QuantifyImage:[\n",
    "        ImageConvEncoder,\n",
    "    ],\n",
    "    QuantifyCategory:[\n",
    "        CategoryEncoder,\n",
    "    ],\n",
    "    QuantifyText:[\n",
    "        TransformerEncoder,\n",
    "    ],\n",
    "    QuantifyNum:[\n",
    "        Empty,\n",
    "    ],\n",
    "})\n",
    "QUANTIFY_2_EXIT_MAP = dict({\n",
    "    QuantifyCategory:[\n",
    "        CategoryTop,\n",
    "    ],\n",
    "    QuantifyNum:[\n",
    "        RegressionTop,\n",
    "    ],\n",
    "})\n",
    "\n",
    "# all entry and exit model\n",
    "ENTRY_ALL = dict(\n",
    "    ImageConvEncoder=ImageConvEncoder,\n",
    "    CategoryEncoder=CategoryEncoder,\n",
    "    TransformerEncoder=TransformerEncoder,\n",
    "    Empty=Empty,\n",
    ")\n",
    "EXIT_ALL = dict(\n",
    "    CategoryTop=CategoryTop,\n",
    "    RegressionTop=RegressionTop,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_models(quantify, cls_options, model_conf:str='x_models'):\n",
    "    def config_model(ModelClass=cls_options):\n",
    "        def starting_cls(kwargs):\n",
    "            global phase\n",
    "            if model_conf in phase:\n",
    "                models = phase[model_conf]\n",
    "            else:\n",
    "                models = dict()\n",
    "            models[quantify.src] = dict(\n",
    "            model_name=ModelClass.__name__,\n",
    "            src=quantify.src,\n",
    "            kwargs=kwargs,\n",
    "            )\n",
    "            phase[model_conf] = models\n",
    "        ia = InteractiveAnnotations(\n",
    "            ModelClass.from_quantify,\n",
    "            description=\"Okay\",\n",
    "            icon='rocket',\n",
    "            button_style='success')\n",
    "            \n",
    "        ia.register_callback(starting_cls)\n",
    "        display(ia.vbox)\n",
    "    inter = interact_manual(config_model)\n",
    "    reconfig_manual_interact(\n",
    "        inter.widget,\n",
    "        description=\"Yes!\", icon=\"cube\", button_style='info')\n",
    "    return inter\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_model(quantify_dict: Dict[str, Quantify]):\n",
    "    global phase\n",
    "    x_models = dict()\n",
    "    y_models = dict()\n",
    "    for src, quantify in quantify_dict.items():\n",
    "        if quantify.is_x:\n",
    "            entry_cls_options = dict(\n",
    "                (q.__name__, q)\n",
    "                for q in QUANTIFY_2_ENTRY_MAP.get(quantify.__class__))\n",
    "\n",
    "            if entry_cls_options is None:\n",
    "                print(f\"We do not support {quantify.__class__} as X data\")\n",
    "                continue\n",
    "            display(HTML(f\"\"\"\n",
    "            <h3 class='text-primary'>Choose Model For X Column:\n",
    "            <strong>{src}</strong></h3>\"\"\"))\n",
    "            choose_models(quantify, entry_cls_options, \"x_models\")\n",
    "    for src, quantify in quantify_dict.items():\n",
    "        if quantify.is_x == False:\n",
    "            exit_cls_options = dict(\n",
    "                (q.__name__, q)\n",
    "                for q in QUANTIFY_2_EXIT_MAP.get(quantify.__class__))\n",
    "            if entry_cls_options is None:\n",
    "                print(f\"We do not support {quantify.__class__} as Y data\")\n",
    "            display(HTML(f\"\"\"\n",
    "            <h3 class='text-danger'>Choose Model For Y Column:\n",
    "            <strong>{src}</strong></h3>\"\"\"))\n",
    "            choose_models(quantify, exit_cls_options, \"y_models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntryDict(nn.Module):\n",
    "    \"\"\"\n",
    "    Create entry parts for different columns\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        phase: Phase,\n",
    "        qdict: Dict[str, EntryModel]\n",
    "    ):\n",
    "        super().__init__()\n",
    "        model_dict = nn.ModuleDict()\n",
    "        for src, model_cfg in phase['x_models'].items():\n",
    "            quantify = qdict[src]\n",
    "            \n",
    "            # find column class\n",
    "            model_cls = ENTRY_ALL[model_cfg['model_name']]\n",
    "            # the kwargs to start the column model object\n",
    "            model_kwargs = model_cfg['kwargs']\n",
    "            # the model object\n",
    "            model = model_cls.from_quantify(quantify, **model_kwargs)\n",
    "            \n",
    "            # add the model by column name\n",
    "            model_dict[src] = model\n",
    "        \n",
    "        # calculate the output size for dimention 1 (after concatenation)\n",
    "        self.out_features = sum(\n",
    "            list(model.out_features for src, model in model_dict.items()))\n",
    "        self.model_dict = model_dict\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        outputs = []\n",
    "        for src, model in self.model_dict.items():\n",
    "            # input data for column\n",
    "            src_input = inputs[src]\n",
    "            \n",
    "            # forward pass for column_model(column_data)\n",
    "            outputs.append(model(src_input))\n",
    "        # concat the results\n",
    "        return torch.cat(outputs, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AssembledModel(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        phase: Phase,\n",
    "        qdict: Dict[str, EntryModel],\n",
    "        entry_lr: LIST(options=[1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6], default=1e-4)=1e-4,\n",
    "        exit_lr: LIST(options=[1e-1, 1e-2, 1e-3, 1e-4, ], default=1e-3)=1e-3,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.entry_lr = entry_lr\n",
    "        self.exit_lr = exit_lr\n",
    "        self.entry_dict = EntryDict(phase, qdict)\n",
    "        exit_cfg = list(phase['y_models'].values())[0]\n",
    "        \n",
    "        self.exit_src = exit_cfg['src']\n",
    "        self.exit_kwargs = exit_cfg['kwargs']\n",
    "        exit_cls = EXIT_ALL[exit_cfg['model_name']]\n",
    "        \n",
    "        exit_quantify = qdict[self.exit_src]\n",
    "        \n",
    "        self.exit_part = exit_cls.from_quantify(\n",
    "            exit_quantify,self.entry_dict, **self.exit_kwargs)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        vec = self.entry_dict(inputs)\n",
    "        return self.exit_part(vec)\n",
    "    \n",
    "    def loss_step(self, inputs):\n",
    "        vec = self.entry_dict(inputs)\n",
    "        return self.exit_part.loss_step(vec, inputs[self.exit_src])\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        rt = self.loss_step(batch)\n",
    "        for k, v in rt.items():\n",
    "            if v.numel()==1:\n",
    "                self.log(f\"trn_{k}\", v)\n",
    "        return rt['loss']\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        rt = self.loss_step(batch)\n",
    "        for k, v in rt.items():\n",
    "            if v.numel()==1:\n",
    "                self.log(f\"val_{k}\", v)\n",
    "        return rt['loss']\n",
    "    \n",
    "    def configure_optimizers(self,):\n",
    "        param_groups = [\n",
    "            {\"params\":self.entry_dict.parameters(), \"lr\":self.entry_lr},\n",
    "            {\"params\":self.exit_part.parameters(), \"lr\":self.exit_lr},\n",
    "        ]\n",
    "        return torch.optim.Adam(param_groups)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(phase, qdict):\n",
    "    if \"y_models\" in phase:\n",
    "        y_models = phase[\"y_models\"]\n",
    "        if len(y_models)>1:\n",
    "            raise ValueError(\"Multiple targets are not supported by now\")\n",
    "        else:\n",
    "            return AssembledModel(phase, qdict)\n",
    "    else:\n",
    "        raise ValueError(\"phase must contain 'y_models' configuration for now\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_slug_name(phase):\n",
    "    xs = '-'.join(list(q['src'] for q in phase['quantify'] if q[\"x\"]))\n",
    "    ys = '-'.join(list(q['src'] for q in phase['quantify'] if q[\"x\"]==False))\n",
    "    return '_'.join([xs,'to',ys])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a vivid **name** for the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_trainer(\n",
    "    project:STR(default=\"default\",) = \"default\",\n",
    "    tensorboard: BOOL(default=True)=True,\n",
    "    show_metric: BOOL(default=True)=True,\n",
    "    max_epochs: INT(min_=1, max_=200, default=5)=5,\n",
    "    use_gpu:BOOL(default=True)=True,\n",
    "):\n",
    "    global phase\n",
    "    if project=='default':\n",
    "        global PROJECT\n",
    "        if str(PROJECT)!=\"None\":\n",
    "            project = PROJECT\n",
    "        else:\n",
    "            project = \"./project\"\n",
    "    project = Path(project)\n",
    "    TASK_SLUG = make_slug_name(phase)\n",
    "    csv_logger = pl.loggers.CSVLogger(project/\"csv_log\", name = TASK_SLUG, )\n",
    "    loggers = [\n",
    "        csv_logger\n",
    "    ]\n",
    "    if tensorboard:\n",
    "        loggers.append(\n",
    "            pl.loggers.TensorBoardLogger(save_dir=project/'tensorboard', name=TASK_SLUG)\n",
    "        )\n",
    "    rt = dict(\n",
    "        max_epochs = max_epochs,\n",
    "        logger =loggers)\n",
    "    callbacks = []\n",
    "    if show_metric:\n",
    "        callbacks.append(\n",
    "            DataFrameMetricsCallback())\n",
    "        \n",
    "    rt.update({\"callbacks\":callbacks})\n",
    "    \n",
    "    if use_gpu:\n",
    "        rt.update(dict(gpus=1))\n",
    "#     rt.update(dict(\n",
    "#         auto_select_gpus=True,\n",
    "#     ))\n",
    "    return rt\n",
    "\n",
    "def run_training(final_model, datamodule):\n",
    "    def set_trainer_callback(kwargs):\n",
    "        trainer_kwargs = set_trainer(**kwargs)\n",
    "        trainer = pl.Trainer(**trainer_kwargs)\n",
    "        trainer.fit(final_model, datamodule=datamodule)\n",
    "        return trainer\n",
    "    return set_trainer_callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Load all the code above in one shot, the demo starts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra helpers\n",
    "> These are helper function relate to the task, ```only``` to modify the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_creator_image_folder(path: Path)-> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create a dataframe ,\n",
    "    Which list all the image path under a system folder\n",
    "    \"\"\"\n",
    "    path = Path(path)\n",
    "    files = []\n",
    "    formats = [\"jpg\",\"jpeg\",\"png\"]\n",
    "    for fmt in formats:\n",
    "        files.extend(path.rglob(f\"*.{fmt.lower()}\"))\n",
    "        files.extend(path.rglob(f\"*.{fmt.upper()}\"))\n",
    "    return pd.DataFrame({\"path\":files}).sample(frac=1.).reset_index(drop=True)\n",
    "\n",
    "import random\n",
    "def noise():\n",
    "    return random.random()*.1\n",
    "\n",
    "def turn_bear_dataset_to_regression(base_df):\n",
    "    base_df[\"grizzly_score\"] = base_df['path'].apply(\n",
    "        lambda x: .9 +noise()  if Path(x).parent.name=='grizzly' else .1+noise())\n",
    "    return base_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEAR_DATASET = HOME/\"Downloads\"/\"bear_dataset\"\n",
    "BEAR_DATASET = Path(\"/GCI/data/bear_dataset\")\n",
    "ROTTEN_TOMATOES = Path(\"/GCI/data/rttmt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose one of the following to run "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The bear üêª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df = df_creator_image_folder(BEAR_DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df = turn_bear_dataset_to_regression(base_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The rotten tomatoes üçÖ üé¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rotten_tomatoes_link</th>\n",
       "      <th>critic_name</th>\n",
       "      <th>top_critic</th>\n",
       "      <th>publisher_name</th>\n",
       "      <th>review_type</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Ben McEachen</td>\n",
       "      <td>False</td>\n",
       "      <td>Sunday Mail (Australia)</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>0.700</td>\n",
       "      <td>2010-02-09</td>\n",
       "      <td>Whether audiences will get behind The Lightnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Nick Schager</td>\n",
       "      <td>False</td>\n",
       "      <td>Slant Magazine</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>0.250</td>\n",
       "      <td>2010-02-10</td>\n",
       "      <td>Harry Potter knockoffs don't come more transpa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Bill Goodykoontz</td>\n",
       "      <td>True</td>\n",
       "      <td>Arizona Republic</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>0.700</td>\n",
       "      <td>2010-02-10</td>\n",
       "      <td>Percy Jackson isn't a great movie, but it's a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Jim Schembri</td>\n",
       "      <td>True</td>\n",
       "      <td>The Age (Australia)</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>0.600</td>\n",
       "      <td>2010-02-10</td>\n",
       "      <td>Crammed with dragons, set-destroying fights an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Mark Adams</td>\n",
       "      <td>False</td>\n",
       "      <td>Daily Mirror (UK)</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>0.800</td>\n",
       "      <td>2010-02-10</td>\n",
       "      <td>This action-packed fantasy adventure, based on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108237</th>\n",
       "      <td>m/bottle_shock</td>\n",
       "      <td>Phil Villarreal</td>\n",
       "      <td>False</td>\n",
       "      <td>Arizona Daily Star</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>0.500</td>\n",
       "      <td>2008-08-29</td>\n",
       "      <td>It might have worked better as a documentary, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108238</th>\n",
       "      <td>m/bottle_shock</td>\n",
       "      <td>Todd Gilchrist</td>\n",
       "      <td>False</td>\n",
       "      <td>IGN Movies</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>0.400</td>\n",
       "      <td>2008-08-29</td>\n",
       "      <td>Bottle Shock feels more like an excuse to exer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108239</th>\n",
       "      <td>m/bottle_shock</td>\n",
       "      <td>Austin Kennedy</td>\n",
       "      <td>False</td>\n",
       "      <td>Sin Magazine</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>0.625</td>\n",
       "      <td>2008-09-02</td>\n",
       "      <td>I was slightly involved towards the end, but t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108240</th>\n",
       "      <td>m/bottle_shock</td>\n",
       "      <td>Sean P. Means</td>\n",
       "      <td>False</td>\n",
       "      <td>Salt Lake Tribune</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>0.500</td>\n",
       "      <td>2008-09-05</td>\n",
       "      <td>Flat, musty and with a hint of flopsweat.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108241</th>\n",
       "      <td>m/bottle_shock</td>\n",
       "      <td>Pete Hammond</td>\n",
       "      <td>False</td>\n",
       "      <td>Hollywood.com</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>0.800</td>\n",
       "      <td>2008-10-01</td>\n",
       "      <td>One of the year's most entertaining films.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108242 rows √ó 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       rotten_tomatoes_link       critic_name  top_critic  \\\n",
       "0                 m/0814255      Ben McEachen       False   \n",
       "1                 m/0814255      Nick Schager       False   \n",
       "2                 m/0814255  Bill Goodykoontz        True   \n",
       "3                 m/0814255      Jim Schembri        True   \n",
       "4                 m/0814255        Mark Adams       False   \n",
       "...                     ...               ...         ...   \n",
       "108237       m/bottle_shock   Phil Villarreal       False   \n",
       "108238       m/bottle_shock    Todd Gilchrist       False   \n",
       "108239       m/bottle_shock    Austin Kennedy       False   \n",
       "108240       m/bottle_shock     Sean P. Means       False   \n",
       "108241       m/bottle_shock      Pete Hammond       False   \n",
       "\n",
       "                 publisher_name review_type  review_score review_date  \\\n",
       "0       Sunday Mail (Australia)       Fresh         0.700  2010-02-09   \n",
       "1                Slant Magazine      Rotten         0.250  2010-02-10   \n",
       "2              Arizona Republic       Fresh         0.700  2010-02-10   \n",
       "3           The Age (Australia)       Fresh         0.600  2010-02-10   \n",
       "4             Daily Mirror (UK)       Fresh         0.800  2010-02-10   \n",
       "...                         ...         ...           ...         ...   \n",
       "108237       Arizona Daily Star      Rotten         0.500  2008-08-29   \n",
       "108238               IGN Movies      Rotten         0.400  2008-08-29   \n",
       "108239             Sin Magazine      Rotten         0.625  2008-09-02   \n",
       "108240        Salt Lake Tribune      Rotten         0.500  2008-09-05   \n",
       "108241            Hollywood.com       Fresh         0.800  2008-10-01   \n",
       "\n",
       "                                           review_content  \n",
       "0       Whether audiences will get behind The Lightnin...  \n",
       "1       Harry Potter knockoffs don't come more transpa...  \n",
       "2       Percy Jackson isn't a great movie, but it's a ...  \n",
       "3       Crammed with dragons, set-destroying fights an...  \n",
       "4       This action-packed fantasy adventure, based on...  \n",
       "...                                                   ...  \n",
       "108237  It might have worked better as a documentary, ...  \n",
       "108238  Bottle Shock feels more like an excuse to exer...  \n",
       "108239  I was slightly involved towards the end, but t...  \n",
       "108240          Flat, musty and with a hint of flopsweat.  \n",
       "108241         One of the year's most entertaining films.  \n",
       "\n",
       "[108242 rows x 8 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the rotten tomatoes dataset, we are not using every line\n",
    "base_df = pd.read_csv(ROTTEN_TOMATOES/'critic_reviews.csv', nrows=200000)\n",
    "base_df = base_df[~base_df['review_score'].isna()].reset_index(drop=True)\n",
    "base_df = base_df[~base_df['review_content'].isna()].reset_index(drop=True)\n",
    "base_df = base_df[~base_df['critic_name'].isna()].reset_index(drop=True)\n",
    "\n",
    "base_df = base_df[base_df['review_score'].apply(lambda x: \"/\" in x)].reset_index(drop=True)\n",
    "\n",
    "base_df['review_score'] = base_df['review_score'].apply(eval)\n",
    "\n",
    "base_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where the model & config is going to end up:\n",
    "a PROJECT folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME = Path(os.environ['HOME'])\n",
    "# PROJECT = Path(\"./project\")\n",
    "# PROJECT = Path(\"./project/image_regression\")\n",
    "# PROJECT = Path(\"./project/rotten1\")\n",
    "PROJECT = Path(\"./project/rotten_text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start of the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiate the ```phase``` to track the configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"quantify\": [\n",
      "    {\n",
      "      \"src\": \"review_content\",\n",
      "      \"x\": true,\n",
      "      \"kwargs\": {\n",
      "        \"pretrained\": \"bert-base-cased\",\n",
      "        \"max_length\": 392,\n",
      "        \"padding\": \"max_length\",\n",
      "        \"return_token_type_ids\": true,\n",
      "        \"return_attention_mask\": true,\n",
      "        \"return_offsets_mapping\": false\n",
      "      },\n",
      "      \"quantify\": \"QuantifyText\"\n",
      "    },\n",
      "    {\n",
      "      \"src\": \"publisher_name\",\n",
      "      \"x\": true,\n",
      "      \"kwargs\": {\n",
      "        \"min_frequency\": 1\n",
      "      },\n",
      "      \"quantify\": \"QuantifyCategory\"\n",
      "    },\n",
      "    {\n",
      "      \"src\": \"review_score\",\n",
      "      \"x\": false,\n",
      "      \"kwargs\": {},\n",
      "      \"quantify\": \"QuantifyNum\"\n",
      "    }\n",
      "  ],\n",
      "  \"batch_level\": {\n",
      "    \"valid_ratio\": 0.1,\n",
      "    \"batch_size\": 32,\n",
      "    \"shuffle\": true,\n",
      "    \"num_workers\": 0\n",
      "  },\n",
      "  \"x_models\": {\n",
      "    \"review_content\": {\n",
      "      \"model_name\": \"TransformerEncoder\",\n",
      "      \"src\": \"review_content\",\n",
      "      \"kwargs\": {\n",
      "        \"name\": \"bert-base-uncased\",\n",
      "        \"encoder_mode\": true\n",
      "      }\n",
      "    },\n",
      "    \"publisher_name\": {\n",
      "      \"model_name\": \"CategoryEncoder\",\n",
      "      \"src\": \"publisher_name\",\n",
      "      \"kwargs\": {\n",
      "        \"embedding_dim\": 32\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"y_models\": {\n",
      "    \"review_score\": {\n",
      "      \"model_name\": \"RegressionTop\",\n",
      "      \"src\": \"review_score\",\n",
      "      \"kwargs\": {}\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "load_phase()\n",
    "# phase = Phase()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add more columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>108242 rows of data, example table</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rotten_tomatoes_link</th>\n",
       "      <th>critic_name</th>\n",
       "      <th>top_critic</th>\n",
       "      <th>publisher_name</th>\n",
       "      <th>review_type</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80685</th>\n",
       "      <td>m/attack_the_block</td>\n",
       "      <td>Ben Rawson-Jones</td>\n",
       "      <td>False</td>\n",
       "      <td>Digital Spy</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>0.800</td>\n",
       "      <td>2011-07-14</td>\n",
       "      <td>Attack the Block is exactly the kind of distin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60337</th>\n",
       "      <td>m/african_cats</td>\n",
       "      <td>Jim Lane</td>\n",
       "      <td>False</td>\n",
       "      <td>Sacramento News &amp; Review</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>0.600</td>\n",
       "      <td>2011-04-29</td>\n",
       "      <td>... fascinating nature photography.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48765</th>\n",
       "      <td>m/4_months_3_weeks_and_2_days</td>\n",
       "      <td>Frederic and Mary Ann Brussat</td>\n",
       "      <td>False</td>\n",
       "      <td>Spirituality &amp; Practice</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>0.800</td>\n",
       "      <td>2007-09-30</td>\n",
       "      <td>A riveting and realistic Romanian film about a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40323</th>\n",
       "      <td>m/1212410-get_him_to_the_greek</td>\n",
       "      <td>David Nusair</td>\n",
       "      <td>False</td>\n",
       "      <td>Reel Film Reviews</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>0.375</td>\n",
       "      <td>2010-06-13</td>\n",
       "      <td>...Get Him to the Greek ultimately overstays i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8343</th>\n",
       "      <td>m/10011815-hole</td>\n",
       "      <td>Graham Young</td>\n",
       "      <td>False</td>\n",
       "      <td>Birmingham Post</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>0.800</td>\n",
       "      <td>2010-09-22</td>\n",
       "      <td>An enjoyable compendium with some good effects...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 rotten_tomatoes_link                    critic_name  \\\n",
       "80685              m/attack_the_block               Ben Rawson-Jones   \n",
       "60337                  m/african_cats                       Jim Lane   \n",
       "48765   m/4_months_3_weeks_and_2_days  Frederic and Mary Ann Brussat   \n",
       "40323  m/1212410-get_him_to_the_greek                   David Nusair   \n",
       "8343                  m/10011815-hole                   Graham Young   \n",
       "\n",
       "       top_critic            publisher_name review_type  review_score  \\\n",
       "80685       False               Digital Spy       Fresh         0.800   \n",
       "60337       False  Sacramento News & Review       Fresh         0.600   \n",
       "48765       False   Spirituality & Practice       Fresh         0.800   \n",
       "40323       False         Reel Film Reviews      Rotten         0.375   \n",
       "8343        False           Birmingham Post       Fresh         0.800   \n",
       "\n",
       "      review_date                                     review_content  \n",
       "80685  2011-07-14  Attack the Block is exactly the kind of distin...  \n",
       "60337  2011-04-29                ... fascinating nature photography.  \n",
       "48765  2007-09-30  A riveting and realistic Romanian film about a...  \n",
       "40323  2010-06-13  ...Get Him to the Greek ultimately overstays i...  \n",
       "8343   2010-09-22  An enjoyable compendium with some good effects...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "174f15f9cefe43bcaa2043f9d9ab277d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<hr>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cdec24638874d1e98f70cdcbfe89a7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MoreOrLess()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbb659303b9c4ea7806b584d8e7c4925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='src', options=('[all_columns]', 'rotten_tomatoes_link', 'critic_na‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_enrich(base_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rotten_tomatoes_link</th>\n",
       "      <th>critic_name</th>\n",
       "      <th>top_critic</th>\n",
       "      <th>publisher_name</th>\n",
       "      <th>review_type</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Ben McEachen</td>\n",
       "      <td>False</td>\n",
       "      <td>Sunday Mail (Australia)</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>0.700</td>\n",
       "      <td>2010-02-09</td>\n",
       "      <td>Whether audiences will get behind The Lightnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Nick Schager</td>\n",
       "      <td>False</td>\n",
       "      <td>Slant Magazine</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>0.250</td>\n",
       "      <td>2010-02-10</td>\n",
       "      <td>Harry Potter knockoffs don't come more transpa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Bill Goodykoontz</td>\n",
       "      <td>True</td>\n",
       "      <td>Arizona Republic</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>0.700</td>\n",
       "      <td>2010-02-10</td>\n",
       "      <td>Percy Jackson isn't a great movie, but it's a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Jim Schembri</td>\n",
       "      <td>True</td>\n",
       "      <td>The Age (Australia)</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>0.600</td>\n",
       "      <td>2010-02-10</td>\n",
       "      <td>Crammed with dragons, set-destroying fights an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Mark Adams</td>\n",
       "      <td>False</td>\n",
       "      <td>Daily Mirror (UK)</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>0.800</td>\n",
       "      <td>2010-02-10</td>\n",
       "      <td>This action-packed fantasy adventure, based on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108237</th>\n",
       "      <td>m/bottle_shock</td>\n",
       "      <td>Phil Villarreal</td>\n",
       "      <td>False</td>\n",
       "      <td>Arizona Daily Star</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>0.500</td>\n",
       "      <td>2008-08-29</td>\n",
       "      <td>It might have worked better as a documentary, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108238</th>\n",
       "      <td>m/bottle_shock</td>\n",
       "      <td>Todd Gilchrist</td>\n",
       "      <td>False</td>\n",
       "      <td>IGN Movies</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>0.400</td>\n",
       "      <td>2008-08-29</td>\n",
       "      <td>Bottle Shock feels more like an excuse to exer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108239</th>\n",
       "      <td>m/bottle_shock</td>\n",
       "      <td>Austin Kennedy</td>\n",
       "      <td>False</td>\n",
       "      <td>Sin Magazine</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>0.625</td>\n",
       "      <td>2008-09-02</td>\n",
       "      <td>I was slightly involved towards the end, but t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108240</th>\n",
       "      <td>m/bottle_shock</td>\n",
       "      <td>Sean P. Means</td>\n",
       "      <td>False</td>\n",
       "      <td>Salt Lake Tribune</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>0.500</td>\n",
       "      <td>2008-09-05</td>\n",
       "      <td>Flat, musty and with a hint of flopsweat.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108241</th>\n",
       "      <td>m/bottle_shock</td>\n",
       "      <td>Pete Hammond</td>\n",
       "      <td>False</td>\n",
       "      <td>Hollywood.com</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>0.800</td>\n",
       "      <td>2008-10-01</td>\n",
       "      <td>One of the year's most entertaining films.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108242 rows √ó 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       rotten_tomatoes_link       critic_name  top_critic  \\\n",
       "0                 m/0814255      Ben McEachen       False   \n",
       "1                 m/0814255      Nick Schager       False   \n",
       "2                 m/0814255  Bill Goodykoontz        True   \n",
       "3                 m/0814255      Jim Schembri        True   \n",
       "4                 m/0814255        Mark Adams       False   \n",
       "...                     ...               ...         ...   \n",
       "108237       m/bottle_shock   Phil Villarreal       False   \n",
       "108238       m/bottle_shock    Todd Gilchrist       False   \n",
       "108239       m/bottle_shock    Austin Kennedy       False   \n",
       "108240       m/bottle_shock     Sean P. Means       False   \n",
       "108241       m/bottle_shock      Pete Hammond       False   \n",
       "\n",
       "                 publisher_name review_type  review_score review_date  \\\n",
       "0       Sunday Mail (Australia)       Fresh         0.700  2010-02-09   \n",
       "1                Slant Magazine      Rotten         0.250  2010-02-10   \n",
       "2              Arizona Republic       Fresh         0.700  2010-02-10   \n",
       "3           The Age (Australia)       Fresh         0.600  2010-02-10   \n",
       "4             Daily Mirror (UK)       Fresh         0.800  2010-02-10   \n",
       "...                         ...         ...           ...         ...   \n",
       "108237       Arizona Daily Star      Rotten         0.500  2008-08-29   \n",
       "108238               IGN Movies      Rotten         0.400  2008-08-29   \n",
       "108239             Sin Magazine      Rotten         0.625  2008-09-02   \n",
       "108240        Salt Lake Tribune      Rotten         0.500  2008-09-05   \n",
       "108241            Hollywood.com       Fresh         0.800  2008-10-01   \n",
       "\n",
       "                                           review_content  \n",
       "0       Whether audiences will get behind The Lightnin...  \n",
       "1       Harry Potter knockoffs don't come more transpa...  \n",
       "2       Percy Jackson isn't a great movie, but it's a ...  \n",
       "3       Crammed with dragons, set-destroying fights an...  \n",
       "4       This action-packed fantasy adventure, based on...  \n",
       "...                                                   ...  \n",
       "108237  It might have worked better as a documentary, ...  \n",
       "108238  Bottle Shock feels more like an excuse to exer...  \n",
       "108239  I was slightly involved towards the end, but t...  \n",
       "108240          Flat, musty and with a hint of flopsweat.  \n",
       "108241         One of the year's most entertaining films.  \n",
       "\n",
       "[108242 rows x 8 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execute_enrich(base_df, phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rotten_tomatoes_link': 'm/0814255',\n",
       " 'critic_name': 'Nick Schager',\n",
       " 'top_critic': False,\n",
       " 'publisher_name': 'Slant Magazine',\n",
       " 'review_type': 'Rotten',\n",
       " 'review_score': 0.25,\n",
       " 'review_date': '2010-02-10',\n",
       " 'review_content': \"Harry Potter knockoffs don't come more transparent and slapdash than this wannabe-franchise jumpstarter directed by Chris Columbus.\"}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = TaiChiDataset(base_df)\n",
    "ds[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose columns as x, y\n",
    "And how do we quantify them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>108242 rows of data, example table</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rotten_tomatoes_link</th>\n",
       "      <th>critic_name</th>\n",
       "      <th>top_critic</th>\n",
       "      <th>publisher_name</th>\n",
       "      <th>review_type</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>104893</th>\n",
       "      <td>m/blue_car</td>\n",
       "      <td>James Rocchi</td>\n",
       "      <td>False</td>\n",
       "      <td>Netflix</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>0.80</td>\n",
       "      <td>2003-05-08</td>\n",
       "      <td>Moody, thoughtful drama is a brilliant debut f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4702</th>\n",
       "      <td>m/10009355-sugar</td>\n",
       "      <td>Avi Offer</td>\n",
       "      <td>False</td>\n",
       "      <td>NYC Movie Guru</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>0.55</td>\n",
       "      <td>2009-04-03</td>\n",
       "      <td>An often engaging drama that tackles provocati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65660</th>\n",
       "      <td>m/all_the_queens_men</td>\n",
       "      <td>Moira MacDonald</td>\n",
       "      <td>True</td>\n",
       "      <td>Seattle Times</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2002-10-25</td>\n",
       "      <td>It all feels like a Monty Python sketch gone h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37246</th>\n",
       "      <td>m/1202804-green_zone</td>\n",
       "      <td>Liz Braun</td>\n",
       "      <td>False</td>\n",
       "      <td>Jam! Movies</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>0.40</td>\n",
       "      <td>2010-03-12</td>\n",
       "      <td>You might want to pick up the book and skip th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58170</th>\n",
       "      <td>m/absolutely_fabulous_the_movie</td>\n",
       "      <td>Jonathan W. Hickman</td>\n",
       "      <td>False</td>\n",
       "      <td>The Newnan Times-Herald</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2016-07-22</td>\n",
       "      <td>Never quite as funny or as consistently entert...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   rotten_tomatoes_link          critic_name  top_critic  \\\n",
       "104893                       m/blue_car         James Rocchi       False   \n",
       "4702                   m/10009355-sugar            Avi Offer       False   \n",
       "65660              m/all_the_queens_men      Moira MacDonald        True   \n",
       "37246              m/1202804-green_zone            Liz Braun       False   \n",
       "58170   m/absolutely_fabulous_the_movie  Jonathan W. Hickman       False   \n",
       "\n",
       "                 publisher_name review_type  review_score review_date  \\\n",
       "104893                  Netflix       Fresh          0.80  2003-05-08   \n",
       "4702             NYC Movie Guru      Rotten          0.55  2009-04-03   \n",
       "65660             Seattle Times      Rotten          0.25  2002-10-25   \n",
       "37246               Jam! Movies      Rotten          0.40  2010-03-12   \n",
       "58170   The Newnan Times-Herald      Rotten          0.50  2016-07-22   \n",
       "\n",
       "                                           review_content  \n",
       "104893  Moody, thoughtful drama is a brilliant debut f...  \n",
       "4702    An often engaging drama that tackles provocati...  \n",
       "65660   It all feels like a Monty Python sketch gone h...  \n",
       "37246   You might want to pick up the book and skip th...  \n",
       "58170   Never quite as funny or as consistently entert...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9534835d4914b9ba6286b48f5f7e25f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<hr>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Please Choose Column</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"color:#666699\">The AI model will try to guess the Y with the input X</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "702ee663972b4768b443f2c86d8112f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MoreOrLess(children=(HBox(children=(Button(button_style='danger', description='Remove', icon='trash', style=Bu‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee3d186731a84a3c9b19d91c381ebebc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='src', options=('rotten_tomatoes_link', 'critic_name', 'top_critic'‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "choose_xy(base_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0b7223dce40412f8a6e25c77e1ea451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.1, description='valid_ratio', max=0.5, min=0.01, step=0.01), Dropdow‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qdict = execute_quantify(base_df, phase)\n",
    "datamodule = execute_datamodule(base_df, qdict, phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(datamodule.train_dataloader()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5900a22a80a48dba1a08ba809be16b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"\\n            <h3 class='text-primary'>Choose Model For X Column:\\n            <strong>review_cont‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc053b5465b64aaf99a9db7c46be0b53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='ModelClass', options={'TransformerEncoder': <class '__main__.Trans‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61dcf187aad644189b3f1433d7d578bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"\\n            <h3 class='text-primary'>Choose Model For X Column:\\n            <strong>publisher_n‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3c5e859d48144289fbcab18845f5bd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='ModelClass', options={'CategoryEncoder': <class '__main__.Category‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7c70cc01af640379580bd9667c11e00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"\\n            <h3 class='text-danger'>Choose Model For Y Column:\\n            <strong>review_type<‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c0700ca3e0f45beaea348618eecea26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='ModelClass', options={'CategoryTop': <class '__main__.CategoryTop'‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_model(qdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "final_model = create_model(phase, qdict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test a forward pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    final_model.loss_step(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the configuration so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_phase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'review_content-publisher_name_to_review_type'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TASK_SLUG = make_slug_name(phase)\n",
    "TASK_SLUG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How we want to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact_intercept(set_trainer, run_training(final_model, datamodule))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "242.073px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
