{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UnpackAI Library Development Plan\n",
    "> What library should we be?\n",
    "This proposal, is more of a branding proposal, targeting people who's going to play with AI, from various back grounds.\n",
    "* That means, we're going to talk about how people view this library, how they think of ```pip install -Uqq unpackai``` like if I have dandroff recengtly and my mind just jump right into the headshoulders.\n",
    "* For ML, currently, the **jump** is about the following, this is not a throught marketing research, just quick examples from a deep learning practitioner:\n",
    "    * Try free structure quickly, do experiments: pytorch\n",
    "    * Goes to production, run model on edge devices, Tensorflow\n",
    "    * Play with GPU accelerated tensor calculation: Jax\n",
    "    * Play with tf but in simpler layer sense: Keras\n",
    "    * Transformer in clean code: Huggingface\n",
    "    * Visualize things with interactive features: Plotly\n",
    "    * Deploy model prototype: streamlit\n",
    "* Surely you think I fail to mention ```fastai```, this is where the **branding goes wrong**, fastai library is bounded tightly with the education. It's considered a good creation along side its famous course, after the education. Its product feature has many limitation: docs too brief, not supporting multi-device training, very limited numbers of callbacks went beyond Jeremy H's own teaching.\n",
    "* Most important of all, ```fastai``` isn't enjoyable to use, **it's just packing many things mentioned in the course**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What we shouldn't be\n",
    "I know the course is life changing for me and I feel very grateful. But let's not be their library.\n",
    "\n",
    "### The pipeline wrapping plan\n",
    "It all started from a notebook, quite like a template notebook we have for the course. A notebook that achieves the data processing, model building, interpretation for a specific DL task.\n",
    "\n",
    "Then came the packaging part, we wrap **dozens of lines of codes**, which scares our kind students, into simple functions, or class.\n",
    "\n",
    "The wrapped functions are simple to use, to look at, it was executed in 1 line mostly. So friendly to our innocent students.\n",
    "\n",
    "This is what a python library is about, right? Wrap things into functions which can be further wraped into even less lines.\n",
    "\n",
    "It's nothing wrong about this approach at first. Some DL task, if need be, can be shrank into **less than 10 lines of codes.**\n",
    "* The 1st line load the data, \n",
    "* the 2nd line set how to transform data, \n",
    "* the 3rd line build/load the model, \n",
    "* the 4th line trained model.\n",
    "* the 5th line interpret the model in various ways\n",
    "\n",
    "Well the above do look like a decent **structure** to start with, then we pave out the tasks, different contributors take different tasks, can be developed in parallel, and we can have the agile/crum/kanban fun to track our progress!\n",
    "\n",
    "Even if we do this, we could build a useful product, no less.\n",
    "\n",
    "#### Bad side about pipeline wrapping plan\n",
    "So so many libraries are doing the same, from awesome people even. They usually end up to the following:\n",
    "* It's a mess of functions, among them many good functions but a mess. It ends up a branding disaster. (**There is no way to answer: what can you library do, in a slogan**)\n",
    "* A model zoo for a specific domain.\n",
    "* Wraping things up means less and less involvement from the user. The user will spend very little time play with the functions, and each function usually achieve very specific task. Actually I do believe there is a equilibrium like:\n",
    "$\\large{UserPlayHours = a * Task Transferability}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The salvation plan is somehow simpler at how we perceive the library:\n",
    "* A library that allows you experiment AI/DL for various tasks\n",
    "\n",
    "**BUT!!!**\n",
    "* Many module with in the pipeline should be dropdown-list/checkbox **Choosable**.\n",
    "* The **level of detail** we let them to play and choose, is the **level of the difficulty** we want them to enjoy\n",
    "\n",
    "### What is level of detail ?\n",
    "Level of details is the level of fuss we want user to focus on, this is the exact part fastai library got **WRONG**, which will explain most of our struggle so far:\n",
    "* It offers smooth/ easy pipelines, for newbies and business people even.\n",
    "* Any amount of reconfigure, is usually way too complicated for such audience\n",
    "* There is a **GAP** between the 2 points above, hence no room for playing\n",
    "\n",
    "#### Keras Example \n",
    "I started my AI journey with Keras, and I love keras by that time, because:\n",
    "* Keras plays with **layers**(eg. Linear, Convolution), its most strenth is at astracting details beneath this level, and let users play with layers. \n",
    "* I spent lots of time, having fun playing with layers\n",
    "* Aside from the things I have to redesign layer, I can deploy almost all kinds of models mentioned in any DL paper (ùëàùë†ùëíùëüùëÉùëôùëéùë¶ùêªùëúùë¢ùëüùë†=ùëé‚àóùëáùëéùë†ùëòùëáùëüùëéùëõùë†ùëìùëíùëüùëéùëèùëñùëôùëñùë°ùë¶)\n",
    "\n",
    "#### Pytorch lightning example\n",
    "Well I moved on to the career team. I have to deal with layer level, I have to deal with different data/forward pipeline. PL is a good library because:\n",
    "* It allows me play with the things I mentioned, but save my energy on things like looping, logging, multidevice training detail etc.\n",
    "* If you see a training notebook built by PL, you'll see very little lines around training template.\n",
    "* You'll find about a lots of lines on the specifications you intend to be different.\n",
    "\n",
    ">The branding image of the examples are simple:\n",
    "* Keras: play TensorFlow in a concept of layers\n",
    "* Pytorch-Lightning: writting less template code\n",
    "\n",
    "#### Unpackai Example\n",
    "For our lib, I intend for them to focus on, exactly the same range of things we want people to learn:\n",
    "* choose the columns they intend to use, in what way\n",
    "* choose the data transformations\n",
    "* choose the loss, the model structure to use (not keras.layer, not nn.module)\n",
    "* hit run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo of such example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, interact_manual\n",
    "from forgebox.imports import *\n",
    "from forgebox.category import Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME = Path(os.environ['HOME'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's skip data download here, it's download, we're not going to reinvent brilliant stuff around download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEAR_DATASET = HOME/\"Downloads\"/\"bear_dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 Everything starts with dataframe\n",
    "\n",
    "For fastai, everything starts from list, an ItemList to be specific. **ImageList** and **TextList** is [**ItemList**](https://fastai1.fast.ai/tutorial.itemlist.html) with some slight enhanced feature.```[üßÇ, üèì, üç∑, üêª]```\n",
    "\n",
    "For the clarity of education, or for simplecity as ultimate form of beauty, we use [**DataFrame**](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html) as starting point, ItemList in table format. In this way, every dataset has the same starting point, even the tabular data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_creator_image_folder(path: Path):\n",
    "    path = Path(path)\n",
    "    files = list(path.rglob(\"*.jpg\"))\n",
    "    files.extend(path.rglob(\"*.JPG\"))\n",
    "    files.extend(path.rglob(\"*.jpeg\"))\n",
    "    files.extend(path.rglob(\"*.JPEG\"))\n",
    "    files.extend(path.rglob(\"*.png\"))\n",
    "    files.extend(path.rglob(\"*.PNG\"))\n",
    "    return pd.DataFrame({\"path\":files}).sample(frac=1.).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "bear_df = df_creator_image_folder(BEAR_DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/xiaochen.zhang/Downloads/bear_dataset/g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/xiaochen.zhang/Downloads/bear_dataset/g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/xiaochen.zhang/Downloads/bear_dataset/t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/xiaochen.zhang/Downloads/bear_dataset/t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/xiaochen.zhang/Downloads/bear_dataset/b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>/Users/xiaochen.zhang/Downloads/bear_dataset/b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>/Users/xiaochen.zhang/Downloads/bear_dataset/g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>/Users/xiaochen.zhang/Downloads/bear_dataset/b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>/Users/xiaochen.zhang/Downloads/bear_dataset/b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>/Users/xiaochen.zhang/Downloads/bear_dataset/g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>522 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  path\n",
       "0    /Users/xiaochen.zhang/Downloads/bear_dataset/g...\n",
       "1    /Users/xiaochen.zhang/Downloads/bear_dataset/g...\n",
       "2    /Users/xiaochen.zhang/Downloads/bear_dataset/t...\n",
       "3    /Users/xiaochen.zhang/Downloads/bear_dataset/t...\n",
       "4    /Users/xiaochen.zhang/Downloads/bear_dataset/b...\n",
       "..                                                 ...\n",
       "517  /Users/xiaochen.zhang/Downloads/bear_dataset/b...\n",
       "518  /Users/xiaochen.zhang/Downloads/bear_dataset/g...\n",
       "519  /Users/xiaochen.zhang/Downloads/bear_dataset/b...\n",
       "520  /Users/xiaochen.zhang/Downloads/bear_dataset/b...\n",
       "521  /Users/xiaochen.zhang/Downloads/bear_dataset/g...\n",
       "\n",
       "[522 rows x 1 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bear_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enrich columns (feature transformation, label extraction)\n",
    "After this step, there will only be **MORE** column ‚ûï"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Callable, Any, Tuple\n",
    "from torchvision import transforms as tfm\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Enrich:\n",
    "    prefer = None\n",
    "    def __call__(self,row):\n",
    "        return row\n",
    "    \n",
    "class EnrichImage(Enrich):\n",
    "    \"\"\"\n",
    "    Create Image column from image path column\n",
    "    \"\"\"\n",
    "    prefer = \"QuantifyImage\"\n",
    "    typing = Image\n",
    "    def __init__(\n",
    "        self,\n",
    "        path_col: str = \"path\",\n",
    "    ):\n",
    "        self.path_col = path_col\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"[Image]\"\n",
    "    \n",
    "    def __call__(self, row):\n",
    "        img = Image.open(row[self.path_col]).convert('RGB')\n",
    "        return img\n",
    "\n",
    "def enrich_parent_as_label(\n",
    "    df: pd.DataFrame,\n",
    "    path_col:str = \"path\",\n",
    "    parent_col:str=\"parent\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Use parent folder name as label\n",
    "    \"\"\"\n",
    "    df[parent_col] = df[path_col].apply(lambda i:Path(i).parent.name)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "bear_df['img'] = EnrichImage('path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>parent</th>\n",
       "      <th>img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/xiaochen.zhang/Downloads/bear_dataset/b...</td>\n",
       "      <td>black</td>\n",
       "      <td>[Image]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/xiaochen.zhang/Downloads/bear_dataset/b...</td>\n",
       "      <td>black</td>\n",
       "      <td>[Image]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/xiaochen.zhang/Downloads/bear_dataset/g...</td>\n",
       "      <td>grizzly</td>\n",
       "      <td>[Image]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/xiaochen.zhang/Downloads/bear_dataset/t...</td>\n",
       "      <td>teddys</td>\n",
       "      <td>[Image]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/xiaochen.zhang/Downloads/bear_dataset/b...</td>\n",
       "      <td>black</td>\n",
       "      <td>[Image]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>/Users/xiaochen.zhang/Downloads/bear_dataset/b...</td>\n",
       "      <td>black</td>\n",
       "      <td>[Image]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>/Users/xiaochen.zhang/Downloads/bear_dataset/b...</td>\n",
       "      <td>black</td>\n",
       "      <td>[Image]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>/Users/xiaochen.zhang/Downloads/bear_dataset/b...</td>\n",
       "      <td>black</td>\n",
       "      <td>[Image]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>/Users/xiaochen.zhang/Downloads/bear_dataset/g...</td>\n",
       "      <td>grizzly</td>\n",
       "      <td>[Image]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>/Users/xiaochen.zhang/Downloads/bear_dataset/g...</td>\n",
       "      <td>grizzly</td>\n",
       "      <td>[Image]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>522 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  path   parent      img\n",
       "0    /Users/xiaochen.zhang/Downloads/bear_dataset/b...    black  [Image]\n",
       "1    /Users/xiaochen.zhang/Downloads/bear_dataset/b...    black  [Image]\n",
       "2    /Users/xiaochen.zhang/Downloads/bear_dataset/g...  grizzly  [Image]\n",
       "3    /Users/xiaochen.zhang/Downloads/bear_dataset/t...   teddys  [Image]\n",
       "4    /Users/xiaochen.zhang/Downloads/bear_dataset/b...    black  [Image]\n",
       "..                                                 ...      ...      ...\n",
       "517  /Users/xiaochen.zhang/Downloads/bear_dataset/b...    black  [Image]\n",
       "518  /Users/xiaochen.zhang/Downloads/bear_dataset/b...    black  [Image]\n",
       "519  /Users/xiaochen.zhang/Downloads/bear_dataset/b...    black  [Image]\n",
       "520  /Users/xiaochen.zhang/Downloads/bear_dataset/g...  grizzly  [Image]\n",
       "521  /Users/xiaochen.zhang/Downloads/bear_dataset/g...  grizzly  [Image]\n",
       "\n",
       "[522 rows x 3 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bear_df = enrich_parent_as_label(bear_df,)\n",
    "bear_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantify: Choose columns as X and Y, put them into number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "code_folding": [
     9,
     30
    ]
   },
   "outputs": [],
   "source": [
    "class Quantify:\n",
    "    is_quantify = True\n",
    "    \"\"\"\n",
    "    Transform list of things to torch tensor\n",
    "    \"\"\"\n",
    "    def __call__(self, list_of_items):\n",
    "        return torch.Tensor(list_of_items)\n",
    "\n",
    "\n",
    "class QuantifyImage(Quantify):\n",
    "    \"\"\"\n",
    "    Transform PIL.Image to tensor\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        image_size: Tuple[int] = (224, 224),\n",
    "        mean_=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ):\n",
    "        self.transform = tfm.Compose([\n",
    "            tfm.Resize(image_size),\n",
    "            tfm.ToTensor(),\n",
    "            tfm.Normalize(mean=mean_, std=std),\n",
    "        ])\n",
    "\n",
    "    def __call__(self, list_of_image):\n",
    "        return self.transform(list_of_image)\n",
    "\n",
    "\n",
    "class QuantifyCategory(Quantify):\n",
    "    \"\"\"\n",
    "    Transform single categorical data to index numbers in pytorch tensors\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, col_name: str, min_frequency: int = 5):\n",
    "        self.col_name = col_name\n",
    "        self.min_frequency = min_frequency\n",
    "\n",
    "    def summarize_category(self, df):\n",
    "        df = pd.DataFrame(df)\n",
    "        value_counts = df.vc(self.col_name)\n",
    "        categories = np.array(\n",
    "            list(value_counts.index[value_counts.values > self.min_frequency]))\n",
    "        self.category = Category(arr=categories, pad_mst=True)\n",
    "        self.num_category = len(self.category)\n",
    "\n",
    "    def __call__(self, list_of_strings):\n",
    "        return torch.LongTensor(self.category.c2i[np.array(list_of_strings)])\n",
    "\n",
    "\n",
    "class QuantifyMultiCategory(Quantify):\n",
    "    \"\"\"\n",
    "    Turn Multi-categorical data to n_hot encoding numbers in pytorch tensors\n",
    "    \"\"\"\n",
    "    def __init__(self, col_name: str):\n",
    "        self.col_name = col_name\n",
    "        \n",
    "QUANTIFY = dict(\n",
    "    Quantify=Quantify,\n",
    "    QuantifyImage=QuantifyImage,\n",
    "    QuantifyCategory=QuantifyCategory,\n",
    "    QuantifyMultiCategory=QuantifyMultiCategory\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Choose your model, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
